{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Notebook 1: Introduction & SAE Levels of Driving Automation\n\n**Session 1: AI-based Perception Systems in Autonomous Vehicles**\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/milinpatel07/Autonomous-Driving_AI-Safety-and-Security/blob/main/AV_Perception_Safety_Workshop/Session_1_AI_Perception_Systems/notebooks/01_Introduction_SAE_Levels.ipynb)\n\n**Author:** Milin Patel  \n**Duration:** ~15 minutes\n\n---\n\n## üéØ Learning Objectives\n\nBy the end of this notebook, you will:\n- ‚úÖ Understand the SAE J3016 standard and its 6 automation levels (0-5)\n- ‚úÖ Differentiate between driver assistance, partial automation, and full autonomy\n- ‚úÖ Identify real-world examples of each automation level\n- ‚úÖ Understand Operational Design Domain (ODD)\n- ‚úÖ Learn the autonomous driving system architecture\n- ‚úÖ Recognize where AI is used in autonomous vehicles\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ SAE J3016: Levels of Driving Automation\n",
    "\n",
    "The **SAE International J3016** standard defines **6 levels** of driving automation, from no automation (Level 0) to full automation (Level 5).\n",
    "\n",
    "### Key Dimensions:\n",
    "1. **What does the system control?** (steering, braking, acceleration)\n",
    "2. **What does the driver do?** (supervise, be ready to intervene, nothing)\n",
    "3. **Where does it work?** (Operational Design Domain - ODD)\n",
    "\n",
    "Let's create an interactive table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SAE J3016 levels table\n",
    "sae_levels = pd.DataFrame({\n",
    "    'Level': [0, 1, 2, 3, 4, 5],\n",
    "    'Name': [\n",
    "        'No Automation',\n",
    "        'Driver Assistance',\n",
    "        'Partial Automation',\n",
    "        'Conditional Automation',\n",
    "        'High Automation',\n",
    "        'Full Automation'\n",
    "    ],\n",
    "    'System Controls': [\n",
    "        'Nothing',\n",
    "        'Steering OR Braking',\n",
    "        'Steering AND Braking',\n",
    "        'All driving tasks (in ODD)',\n",
    "        'All driving tasks (in ODD)',\n",
    "        'All driving tasks (everywhere)'\n",
    "    ],\n",
    "    'Driver Role': [\n",
    "        'Full control',\n",
    "        'Supervise + control',\n",
    "        'Supervise (hands on wheel)',\n",
    "        'Available as fallback',\n",
    "        'Not needed in ODD',\n",
    "        'Not needed anywhere'\n",
    "    ],\n",
    "    'Examples': [\n",
    "        'Traditional car',\n",
    "        'Adaptive Cruise Control',\n",
    "        'Tesla Autopilot, GM Super Cruise',\n",
    "        'Mercedes Drive Pilot (limited)',\n",
    "        'Waymo (Phoenix), Cruise (SF)',\n",
    "        'Does not exist yet'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display the table with styling\n",
    "def color_levels(row):\n",
    "    colors = ['#ffcccc', '#ffe6cc', '#ffffcc', '#e6f2ff', '#ccffcc', '#ccffee']\n",
    "    return [f'background-color: {colors[int(row[\"Level\"])]}']*len(row)\n",
    "\n",
    "styled_table = sae_levels.style.apply(color_levels, axis=1)\n",
    "display(styled_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Critical Distinction: Level 2 vs Level 3\n",
    "\n",
    "**Level 2 (Partial Automation):**\n",
    "- Driver must **continuously supervise**\n",
    "- Driver is **responsible** for safe operation\n",
    "- Hands must be on steering wheel (or ready)\n",
    "- Example: Tesla Autopilot, Mercedes Active Steering Assist\n",
    "\n",
    "**Level 3 (Conditional Automation):**\n",
    "- System drives, driver is **available as fallback**\n",
    "- Driver can look away, but must respond to takeover requests\n",
    "- System is **responsible** during automated mode\n",
    "- Example: Mercedes Drive Pilot (Germany, up to 60 km/h, highways)\n",
    "\n",
    "**Key Insight:** The jump from Level 2 to Level 3 is HUGE in terms of legal responsibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the responsibility shift\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "levels = np.arange(6)\n",
    "driver_responsibility = [100, 90, 80, 30, 0, 0]\n",
    "system_responsibility = [0, 10, 20, 70, 100, 100]\n",
    "\n",
    "ax.bar(levels, driver_responsibility, label='Driver Responsibility', alpha=0.8, color='#ff6b6b')\n",
    "ax.bar(levels, system_responsibility, bottom=driver_responsibility, \n",
    "       label='System Responsibility', alpha=0.8, color='#4ecdc4')\n",
    "\n",
    "ax.set_xlabel('SAE Automation Level', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Responsibility (%)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Responsibility Shift Across SAE Levels', fontsize=16, fontweight='bold')\n",
    "ax.set_xticks(levels)\n",
    "ax.set_xticklabels([f'L{i}' for i in levels])\n",
    "ax.legend(loc='upper right', fontsize=12)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add annotation for Level 2-3 jump\n",
    "ax.annotate('Critical jump!\\nResponsibility shifts', \n",
    "            xy=(2.5, 50), xytext=(3.5, 70),\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05, width=2),\n",
    "            fontsize=12, fontweight='bold', color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Notice the dramatic shift between Level 2 and Level 3!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Operational Design Domain (ODD)\n",
    "\n",
    "**ODD** defines the **specific conditions** under which an automated system is designed to operate safely.\n",
    "\n",
    "### ODD Dimensions:\n",
    "- **Geography:** Highway vs urban vs rural\n",
    "- **Weather:** Clear, rain, fog, snow\n",
    "- **Time:** Day vs night\n",
    "- **Speed:** Maximum operating speed\n",
    "- **Road type:** Marked lanes, traffic signals, etc.\n",
    "\n",
    "**Example ODDs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example ODDs for different systems\n",
    "odd_examples = pd.DataFrame({\n",
    "    'System': [\n",
    "        'Tesla Autopilot',\n",
    "        'Mercedes Drive Pilot',\n",
    "        'Waymo Robotaxi',\n",
    "        'TuSimple Truck'\n",
    "    ],\n",
    "    'SAE Level': [2, 3, 4, 4],\n",
    "    'Geography': [\n",
    "        'Highways with lane markings',\n",
    "        'German highways (specific sections)',\n",
    "        'Phoenix, San Francisco (mapped areas)',\n",
    "        'Highways (point-to-point routes)'\n",
    "    ],\n",
    "    'Weather': [\n",
    "        'Clear, light rain',\n",
    "        'Clear, dry',\n",
    "        'Clear to moderate rain',\n",
    "        'Clear'\n",
    "    ],\n",
    "    'Speed Limit': [\n",
    "        'Up to 140 km/h',\n",
    "        'Up to 60 km/h',\n",
    "        'Up to 72 km/h (45 mph)',\n",
    "        'Highway speeds'\n",
    "    ],\n",
    "    'Time': [\n",
    "        'Day and night',\n",
    "        'Day only',\n",
    "        'Day and night',\n",
    "        'Day preferred'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(odd_examples)\n",
    "\n",
    "print(\"\\nüí° Key Insight: Higher automation (L4/L5) requires VERY specific ODD or must handle ALL conditions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Why ODD Matters for Safety\n",
    "\n",
    "Operating **outside the ODD** can lead to dangerous situations:\n",
    "\n",
    "- **Uber ATG crash (2018):** System struggled with unexpected pedestrian behavior\n",
    "- **Tesla Autopilot incidents:** Drivers enabled on roads without clear lane markings\n",
    "- **Waymo geofencing:** Only operates in thoroughly mapped areas\n",
    "\n",
    "**Safety Principle:** System must either:\n",
    "1. **Detect ODD boundaries** and request takeover/stop, OR\n",
    "2. **Be robust to all scenarios** (Level 5 aspiration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Autonomous Driving System Architecture\n",
    "\n",
    "Autonomous vehicles follow a **sense ‚Üí perceive ‚Üí predict ‚Üí plan ‚Üí act** pipeline.\n",
    "\n",
    "Let's visualize the architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create architecture diagram\n",
    "from matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 6)\n",
    "ax.axis('off')\n",
    "\n",
    "# Module positions and names\n",
    "modules = [\n",
    "    {'name': 'SENSORS\\n\\nCamera\\nLiDAR\\nRadar\\nGPS', 'x': 0.5, 'color': '#ff6b6b'},\n",
    "    {'name': 'PERCEPTION\\n\\nObject Detection\\nClassification\\nTracking\\nLocalization', 'x': 2.5, 'color': '#4ecdc4'},\n",
    "    {'name': 'PREDICTION\\n\\nTrajectory\\nForecast\\nBehavior\\nModeling', 'x': 4.5, 'color': '#45b7d1'},\n",
    "    {'name': 'PLANNING\\n\\nPath\\nPlanning\\nDecision\\nMaking', 'x': 6.5, 'color': '#96ceb4'},\n",
    "    {'name': 'CONTROL\\n\\nSteering\\nBraking\\nAcceleration', 'x': 8.5, 'color': '#feca57'},\n",
    "]\n",
    "\n",
    "# Draw modules\n",
    "for module in modules:\n",
    "    box = FancyBboxPatch((module['x'], 2), 1.5, 2.5, \n",
    "                          boxstyle=\"round,pad=0.1\", \n",
    "                          facecolor=module['color'], \n",
    "                          edgecolor='black', linewidth=2, alpha=0.7)\n",
    "    ax.add_patch(box)\n",
    "    ax.text(module['x'] + 0.75, 3.25, module['name'], \n",
    "            ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Draw arrows\n",
    "for i in range(len(modules)-1):\n",
    "    arrow = FancyArrowPatch((modules[i]['x'] + 1.5, 3.25), \n",
    "                            (modules[i+1]['x'], 3.25),\n",
    "                            arrowstyle='->', mutation_scale=30, \n",
    "                            linewidth=3, color='black')\n",
    "    ax.add_patch(arrow)\n",
    "\n",
    "# Add AI indicators\n",
    "ai_modules = [1, 2]  # Perception and Prediction use heavy AI\n",
    "for idx in ai_modules:\n",
    "    ax.text(modules[idx]['x'] + 0.75, 4.8, 'ü§ñ AI-Heavy', \n",
    "            ha='center', fontsize=11, fontweight='bold', color='darkred')\n",
    "\n",
    "# Title\n",
    "ax.text(5, 5.5, 'Autonomous Driving System Architecture', \n",
    "        ha='center', fontsize=18, fontweight='bold')\n",
    "\n",
    "# Add description\n",
    "ax.text(5, 1.2, 'Data flows left to right: Sensors collect raw data ‚Üí Perception understands environment ‚Üí '\n",
    "        'Prediction forecasts future ‚Üí Planning decides actions ‚Üí Control executes',\n",
    "        ha='center', fontsize=10, style='italic', wrap=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Key Observation: AI is most heavily used in PERCEPTION and PREDICTION modules!\")\n",
    "print(\"   This workshop focuses on PERCEPTION - the foundation of autonomous driving.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Descriptions\n",
    "\n",
    "| Module | Function | AI Usage | Example Tasks |\n",
    "|--------|----------|----------|---------------|\n",
    "| **Sensors** | Collect raw data | None | Capture images, scan LiDAR, measure radar |\n",
    "| **Perception** | Understand environment | ‚úÖ Heavy | Detect cars, pedestrians, lanes, signs |\n",
    "| **Prediction** | Forecast future states | ‚úÖ Heavy | Predict pedestrian trajectory, vehicle intentions |\n",
    "| **Planning** | Decide vehicle actions | üü° Moderate | Route planning, behavior planning, motion planning |\n",
    "| **Control** | Execute commands | Minimal | PID controllers, actuator commands |\n",
    "\n",
    "**Today's Focus:** PERCEPTION - where AI plays the most critical role!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Why AI for Perception?\n",
    "\n",
    "### The Challenge:\n",
    "- Infinite variety of real-world scenarios\n",
    "- Complex, unstructured environments\n",
    "- Real-time processing requirements (30-60 Hz)\n",
    "- Must handle uncertainty and ambiguity\n",
    "\n",
    "### Traditional Approach (Rule-based):\n",
    "```python\n",
    "if (object_height > object_width) and (object_moving):\n",
    "    label = \"pedestrian\"\n",
    "elif (object_rectangular) and (object_has_wheels):\n",
    "    label = \"car\"\n",
    "```\n",
    "\n",
    "**Problems:**\n",
    "- ‚ùå Fails with unusual poses, occlusions, lighting\n",
    "- ‚ùå Requires manual feature engineering\n",
    "- ‚ùå Cannot handle all edge cases\n",
    "\n",
    "### AI/Machine Learning Approach:\n",
    "```python\n",
    "# Train on millions of labeled examples\n",
    "model.train(images, labels)\n",
    "\n",
    "# Model learns patterns automatically\n",
    "prediction = model.predict(new_image)\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- ‚úÖ Learns from data, handles variations\n",
    "- ‚úÖ Generalizes to new scenarios\n",
    "- ‚úÖ Improves with more data\n",
    "\n",
    "**Trade-off:**\n",
    "- ‚ö†Ô∏è Less predictable than rule-based systems\n",
    "- ‚ö†Ô∏è Can fail in unexpected ways (Session 2!)\n",
    "- ‚ö†Ô∏è Requires safety validation (Session 3!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare rule-based vs ML-based approaches\n",
    "comparison = pd.DataFrame({\n",
    "    'Aspect': [\n",
    "        'Development',\n",
    "        'Performance on typical cases',\n",
    "        'Performance on edge cases',\n",
    "        'Explainability',\n",
    "        'Safety validation',\n",
    "        'Improvement over time',\n",
    "        'Computational cost'\n",
    "    ],\n",
    "    'Rule-Based': [\n",
    "        'Manual feature engineering',\n",
    "        'Good (if rules cover case)',\n",
    "        'Poor (cannot anticipate all)',\n",
    "        'High (explicit rules)',\n",
    "        'Easier (test each rule)',\n",
    "        'Manual updates needed',\n",
    "        'Low'\n",
    "    ],\n",
    "    'Machine Learning': [\n",
    "        'Requires large labeled dataset',\n",
    "        'Excellent (learns patterns)',\n",
    "        'Better (generalizes)',\n",
    "        'Low (\"black box\")',\n",
    "        'Difficult (billions of scenarios)',\n",
    "        'Automatic with more data',\n",
    "        'High (GPUs needed)'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(comparison)\n",
    "\n",
    "print(\"\\nüí° Modern autonomous vehicles use ML for perception, but this introduces new safety challenges!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úèÔ∏è Exercise 1: SAE Level Classification\n",
    "\n",
    "**Task:** Classify the following real-world systems by their SAE automation level.\n",
    "\n",
    "1. **Tesla Model 3 with Autopilot** (on highway, driver monitoring with camera)\n",
    "2. **Waymo autonomous taxi** (Phoenix, AZ, no driver)\n",
    "3. **Mercedes-Benz S-Class with Drive Pilot** (German highway, traffic jam, <60 km/h)\n",
    "4. **Honda Civic with Adaptive Cruise Control** (maintains speed and distance)\n",
    "5. **Cruise robotaxi** (San Francisco, no driver, geofenced)\n",
    "6. **BMW 7 Series with Lane Keeping Assist** (steers to keep in lane)\n",
    "\n",
    "**Your answers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in your answers (0-5)\n",
    "your_answers = {\n",
    "    'Tesla Autopilot': None,  # Replace None with your answer (0-5)\n",
    "    'Waymo Phoenix': None,\n",
    "    'Mercedes Drive Pilot': None,\n",
    "    'Honda ACC': None,\n",
    "    'Cruise SF': None,\n",
    "    'BMW Lane Keeping': None\n",
    "}\n",
    "\n",
    "# Uncomment to check your answers\n",
    "# correct_answers = {'Tesla Autopilot': 2, 'Waymo Phoenix': 4, 'Mercedes Drive Pilot': 3, \n",
    "#                    'Honda ACC': 1, 'Cruise SF': 4, 'BMW Lane Keeping': 1}\n",
    "# for system, level in your_answers.items():\n",
    "#     if level == correct_answers[system]:\n",
    "#         print(f\"‚úÖ {system}: Correct! (Level {level})\")\n",
    "#     else:\n",
    "#         print(f\"‚ùå {system}: Incorrect. You said {level}, correct is {correct_answers[system]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úèÔ∏è Exercise 2: ODD Analysis\n",
    "\n",
    "**Scenario:** You are designing a Level 4 autonomous shuttle for a university campus.\n",
    "\n",
    "**Define an appropriate ODD:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your ODD\n",
    "campus_shuttle_odd = {\n",
    "    'Geography': '',  # e.g., \"Campus roads, speed bumps, pedestrian zones\"\n",
    "    'Weather': '',    # e.g., \"Clear, light rain\"\n",
    "    'Speed': '',      # e.g., \"Max 25 km/h\"\n",
    "    'Time': '',       # e.g., \"Daylight hours only\"\n",
    "    'Special_Conditions': ''  # e.g., \"No operation during events\"\n",
    "}\n",
    "\n",
    "print(\"Your ODD for campus shuttle:\")\n",
    "for key, value in campus_shuttle_odd.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Reflection questions (discuss or write down):\n",
    "print(\"\\nü§î Reflection:\")\n",
    "print(\"1. Why did you set these specific boundaries?\")\n",
    "print(\"2. What scenarios might be dangerous outside this ODD?\")\n",
    "print(\"3. How would you detect when the shuttle exits the ODD?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "### SAE Automation Levels\n",
    "- **Level 0-2:** Driver is responsible\n",
    "- **Level 3-5:** System is responsible (within ODD)\n",
    "- **Critical jump:** Level 2 ‚Üí 3 (responsibility shift)\n",
    "\n",
    "### Operational Design Domain (ODD)\n",
    "- Defines **where, when, and how** system operates safely\n",
    "- Higher automation requires either:\n",
    "  - Very specific ODD (Level 4), OR\n",
    "  - Handle all conditions (Level 5 - doesn't exist yet)\n",
    "\n",
    "### System Architecture\n",
    "- **Pipeline:** Sensors ‚Üí Perception ‚Üí Prediction ‚Üí Planning ‚Üí Control\n",
    "- **AI-heavy modules:** Perception and Prediction\n",
    "- **This workshop focus:** Perception (foundation of autonomy)\n",
    "\n",
    "### Why AI for Perception?\n",
    "- Real-world complexity exceeds rule-based systems\n",
    "- ML learns from data, handles variations\n",
    "- **Trade-off:** Less predictable ‚Üí New safety challenges\n",
    "\n",
    "---\n",
    "\n",
    "## üîú Next: Notebook 2 - Sensor Modalities\n",
    "\n",
    "Now that we understand the levels and architecture, let's dive into the **sensors** that enable perception:\n",
    "- Camera\n",
    "- LiDAR  \n",
    "- Radar\n",
    "- Sensor fusion\n",
    "\n",
    "**Ready?** Open `02_Sensor_Modalities_Visualization.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook created by Milin Patel | Hochschule Kempten*  \n",
    "*Last updated: 2025-01-17*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}