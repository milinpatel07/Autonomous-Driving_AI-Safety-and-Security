{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Notebook 6: Pedestrian Detection - A Safety-Critical Case Study\n",
    "\n",
    "**Session 1: AI-based Perception Systems in Autonomous Vehicles**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/milinpatel07/Autonomous-Driving_AI-Safety-and-Security/blob/main/AV_Perception_Safety_Workshop/Session_1_AI_Perception_Systems/notebooks/06_Pedestrian_Detection_Case_Study.ipynb)\n",
    "\n",
    "**Author:** Milin Patel  \n",
    "**Duration:** ~15 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- ‚úÖ Understand why pedestrian detection is safety-critical\n",
    "- ‚úÖ Implement YOLOv8 for pedestrian detection\n",
    "- ‚úÖ Analyze failure cases and edge scenarios\n",
    "- ‚úÖ Link to ISO 26262 safety requirements\n",
    "- ‚úÖ Evaluate detection performance metrics\n",
    "- ‚úÖ Identify mitigation strategies for failures\n",
    "\n",
    "---\n",
    "\n",
    "## üö® Why Pedestrian Detection is Critical\n",
    "\n",
    "**Pedestrians are Vulnerable Road Users (VRUs):**\n",
    "- No protective shell (unlike vehicles)\n",
    "- Unpredictable behavior (children, elderly, distracted)\n",
    "- Small visual signature (hard to detect at distance)\n",
    "- High injury/fatality risk in collisions\n",
    "\n",
    "**Real-World Incidents:**\n",
    "- **Uber ATG (2018):** Failed to detect pedestrian pushing bicycle ‚Üí fatal collision\n",
    "- **Tesla Autopilot (multiple):** Failures in low-light conditions\n",
    "- **Waymo (2023):** Pedestrian struck in autonomous mode\n",
    "\n",
    "**ISO 26262 Classification:**\n",
    "- **ASIL-D** (highest safety level)\n",
    "- Requires redundancy, validation, fail-safe mechanisms\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check if running on Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üîß Running on Google Colab - Installing dependencies...\\n\")\n",
    "    !pip install -q ultralytics opencv-python matplotlib numpy pillow requests pandas seaborn\n",
    "    print(\"‚úÖ Setup complete!\\n\")\n",
    "else:\n",
    "    print(\"üíª Running locally\\n\")\n",
    "\n",
    "print(\"‚úÖ Environment ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Pedestrian Detection Statistics\n",
    "\n",
    "Let's look at real-world pedestrian accident data to understand the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pedestrian fatality data (US, approximate)\n",
    "accident_conditions = pd.DataFrame({\n",
    "    'Condition': ['Daylight', 'Dark (lit)', 'Dark (unlit)', 'Dawn/Dusk', 'Weather'],\n",
    "    'Percentage': [25, 30, 35, 10, 15],  # Overlapping categories\n",
    "    'Risk_Factor': [1.0, 3.5, 7.0, 2.5, 2.0]\n",
    "})\n",
    "\n",
    "# Pedestrian types\n",
    "pedestrian_types = pd.DataFrame({\n",
    "    'Type': ['Adult Walking', 'Child', 'Elderly', 'Cyclist/Scooter', 'Wheelchair', 'Pushing Object'],\n",
    "    'Frequency': [60, 15, 20, 30, 2, 8],\n",
    "    'Detection_Difficulty': [1.0, 1.5, 1.2, 2.0, 2.5, 3.0]  # Relative difficulty\n",
    "})\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Accident conditions\n",
    "axes[0, 0].bar(accident_conditions['Condition'], accident_conditions['Percentage'], \n",
    "               color=plt.cm.Reds(np.linspace(0.3, 0.9, len(accident_conditions))))\n",
    "axes[0, 0].set_ylabel('Accident Percentage (%)', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_title('Pedestrian Accidents by Lighting Condition', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add annotations\n",
    "for i, (cond, pct) in enumerate(zip(accident_conditions['Condition'], accident_conditions['Percentage'])):\n",
    "    axes[0, 0].text(i, pct + 1, f\"{pct}%\", ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Risk factors\n",
    "axes[0, 1].barh(accident_conditions['Condition'], accident_conditions['Risk_Factor'], \n",
    "                color=plt.cm.Oranges(np.linspace(0.3, 0.9, len(accident_conditions))))\n",
    "axes[0, 1].set_xlabel('Relative Risk Factor', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_title('Detection Difficulty by Condition', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "for i, (cond, risk) in enumerate(zip(accident_conditions['Condition'], accident_conditions['Risk_Factor'])):\n",
    "    axes[0, 1].text(risk + 0.1, i, f\"{risk}x\", va='center', fontweight='bold')\n",
    "\n",
    "# 3. Pedestrian types frequency\n",
    "axes[1, 0].bar(range(len(pedestrian_types)), pedestrian_types['Frequency'], \n",
    "               color=plt.cm.Blues(np.linspace(0.3, 0.9, len(pedestrian_types))))\n",
    "axes[1, 0].set_xticks(range(len(pedestrian_types)))\n",
    "axes[1, 0].set_xticklabels(pedestrian_types['Type'], rotation=45, ha='right')\n",
    "axes[1, 0].set_ylabel('Relative Frequency', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_title('Pedestrian Type Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Detection difficulty\n",
    "axes[1, 1].scatter(pedestrian_types['Frequency'], pedestrian_types['Detection_Difficulty'], \n",
    "                  s=200, alpha=0.6, c=range(len(pedestrian_types)), cmap='viridis')\n",
    "axes[1, 1].set_xlabel('Frequency', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Detection Difficulty', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_title('Frequency vs. Detection Difficulty', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add labels\n",
    "for i, row in pedestrian_types.iterrows():\n",
    "    axes[1, 1].annotate(row['Type'], (row['Frequency'], row['Detection_Difficulty']),\n",
    "                       fontsize=8, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Key Findings:\")\n",
    "print(\"   - 65%+ of pedestrian fatalities occur in low-light conditions\")\n",
    "print(\"   - Dark unlit roads: 7x higher risk than daylight\")\n",
    "print(\"   - Non-standard pedestrians (wheelchairs, objects) are hardest to detect\")\n",
    "print(\"\\nüí° Challenge: Systems must work in ALL conditions, including rare ones!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Load YOLOv8 Pedestrian Detector\n",
    "\n",
    "We'll use YOLOv8 trained on COCO dataset (includes 'person' class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 model\n",
    "print(\"Loading YOLOv8n model...\")\n",
    "model = YOLO('yolov8n.pt')  # Nano version for speed\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"\\nModel classes include: {model.names[0]} (person)\")\n",
    "print(f\"Total classes: {len(model.names)}\")\n",
    "\n",
    "# Hugging Face demo link\n",
    "print(\"\\nü§ó Try interactive demo:\")\n",
    "print(\"   https://huggingface.co/spaces/valid999/Yolov8_object_detection\")\n",
    "print(\"   Upload your own images to test pedestrian detection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Test on Various Pedestrian Scenarios\n",
    "\n",
    "Let's test the model on different challenging scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to detect pedestrians\n",
    "def detect_pedestrians(image, conf_threshold=0.25, visualize=True):\n",
    "    \"\"\"\n",
    "    Detect pedestrians in image using YOLOv8.\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array (RGB)\n",
    "        conf_threshold: minimum confidence\n",
    "        visualize: whether to show results\n",
    "    \n",
    "    Returns:\n",
    "        pedestrian_detections: list of detected pedestrians\n",
    "    \"\"\"\n",
    "    # Run inference\n",
    "    start_time = time.time()\n",
    "    results = model.predict(image, conf=conf_threshold, verbose=False)[0]\n",
    "    inference_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    # Filter for 'person' class (class_id = 0 in COCO)\n",
    "    boxes = results.boxes.xyxy.cpu().numpy()\n",
    "    confidences = results.boxes.conf.cpu().numpy()\n",
    "    class_ids = results.boxes.cls.cpu().numpy().astype(int)\n",
    "    \n",
    "    pedestrians = []\n",
    "    for box, conf, cls_id in zip(boxes, confidences, class_ids):\n",
    "        if model.names[cls_id] == 'person':\n",
    "            pedestrians.append({\n",
    "                'bbox': box,\n",
    "                'confidence': conf,\n",
    "                'class': 'person'\n",
    "            })\n",
    "    \n",
    "    if visualize:\n",
    "        # Draw detections\n",
    "        img_vis = image.copy()\n",
    "        for ped in pedestrians:\n",
    "            x1, y1, x2, y2 = ped['bbox'].astype(int)\n",
    "            conf = ped['confidence']\n",
    "            \n",
    "            # Color based on confidence\n",
    "            if conf > 0.7:\n",
    "                color = (0, 255, 0)  # Green - high confidence\n",
    "            elif conf > 0.5:\n",
    "                color = (255, 165, 0)  # Orange - medium\n",
    "            else:\n",
    "                color = (255, 0, 0)  # Red - low confidence\n",
    "            \n",
    "            cv2.rectangle(img_vis, (x1, y1), (x2, y2), color, 3)\n",
    "            cv2.putText(img_vis, f\"Person: {conf:.2f}\", (x1, y1-10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # Display\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plt.imshow(img_vis)\n",
    "        plt.title(f\"Pedestrian Detection - {len(pedestrians)} detected | Inference: {inference_time:.1f}ms\",\n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Detection Summary:\")\n",
    "    print(f\"   - Pedestrians detected: {len(pedestrians)}\")\n",
    "    print(f\"   - Inference time: {inference_time:.1f} ms\")\n",
    "    print(f\"   - FPS: {1000/inference_time:.1f}\")\n",
    "    \n",
    "    if pedestrians:\n",
    "        confidences_list = [p['confidence'] for p in pedestrians]\n",
    "        print(f\"   - Avg confidence: {np.mean(confidences_list):.3f}\")\n",
    "        print(f\"   - Min confidence: {np.min(confidences_list):.3f}\")\n",
    "        print(f\"   - Max confidence: {np.max(confidences_list):.3f}\")\n",
    "    \n",
    "    return pedestrians\n",
    "\n",
    "print(\"‚úÖ Detection function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### Test on Sample Images\n",
    "\n",
    "Let's create synthetic test scenarios representing different challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic pedestrian scenarios\n",
    "def create_pedestrian_scene(scenario='normal', size=(1242, 375)):\n",
    "    \"\"\"\n",
    "    Create synthetic pedestrian scene for testing.\n",
    "    \n",
    "    Scenarios:\n",
    "    - normal: Clear daylight, standing pedestrians\n",
    "    - occluded: Partially hidden pedestrians\n",
    "    - night: Dark background\n",
    "    - crowd: Multiple pedestrians close together\n",
    "    \"\"\"\n",
    "    width, height = size\n",
    "    image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    if scenario == 'normal':\n",
    "        # Clear daylight scene\n",
    "        image[:height//3] = [135, 206, 235]  # Sky\n",
    "        image[height//3:] = [105, 105, 105]  # Road\n",
    "        \n",
    "        # Draw pedestrian silhouettes\n",
    "        pedestrian_positions = [(300, 180), (600, 200), (900, 190)]\n",
    "        for x, y in pedestrian_positions:\n",
    "            # Simple person shape (head + body)\n",
    "            cv2.circle(image, (x, y), 15, (200, 150, 100), -1)  # Head\n",
    "            cv2.rectangle(image, (x-20, y+15), (x+20, y+80), (150, 100, 80), -1)  # Body\n",
    "            cv2.rectangle(image, (x-20, y+80), (x-5, y+130), (100, 80, 60), -1)  # Left leg\n",
    "            cv2.rectangle(image, (x+5, y+80), (x+20, y+130), (100, 80, 60), -1)  # Right leg\n",
    "    \n",
    "    elif scenario == 'occluded':\n",
    "        # Partially occluded pedestrians\n",
    "        image[:height//3] = [135, 206, 235]\n",
    "        image[height//3:] = [105, 105, 105]\n",
    "        \n",
    "        # Draw cars (occluders)\n",
    "        cv2.rectangle(image, (250, 200), (450, 320), (80, 80, 80), -1)\n",
    "        cv2.rectangle(image, (800, 210), (1000, 330), (70, 70, 70), -1)\n",
    "        \n",
    "        # Partially visible pedestrians\n",
    "        cv2.circle(image, (400, 180), 15, (200, 150, 100), -1)\n",
    "        cv2.rectangle(image, (380, 195), (420, 250), (150, 100, 80), -1)\n",
    "    \n",
    "    elif scenario == 'night':\n",
    "        # Dark scene\n",
    "        image[:] = [20, 20, 30]  # Dark background\n",
    "        \n",
    "        # Dim pedestrians\n",
    "        pedestrian_positions = [(400, 200), (700, 210)]\n",
    "        for x, y in pedestrian_positions:\n",
    "            cv2.circle(image, (x, y), 15, (80, 60, 50), -1)\n",
    "            cv2.rectangle(image, (x-20, y+15), (x+20, y+80), (60, 50, 40), -1)\n",
    "            cv2.rectangle(image, (x-20, y+80), (x-5, y+130), (50, 40, 30), -1)\n",
    "            cv2.rectangle(image, (x+5, y+80), (x+20, y+130), (50, 40, 30), -1)\n",
    "    \n",
    "    elif scenario == 'crowd':\n",
    "        # Multiple pedestrians\n",
    "        image[:height//3] = [135, 206, 235]\n",
    "        image[height//3:] = [105, 105, 105]\n",
    "        \n",
    "        pedestrian_positions = [(200, 180), (260, 190), (320, 185), \n",
    "                               (500, 200), (560, 195), (800, 190)]\n",
    "        for x, y in pedestrian_positions:\n",
    "            cv2.circle(image, (x, y), 12, (200, 150, 100), -1)\n",
    "            cv2.rectangle(image, (x-15, y+12), (x+15, y+60), (150, 100, 80), -1)\n",
    "            cv2.rectangle(image, (x-15, y+60), (x-5, y+100), (100, 80, 60), -1)\n",
    "            cv2.rectangle(image, (x+5, y+60), (x+15, y+100), (100, 80, 60), -1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Test scenarios\n",
    "scenarios = ['normal', 'occluded', 'night', 'crowd']\n",
    "\n",
    "print(\"‚ö†Ô∏è Note: These are simplified synthetic images.\")\n",
    "print(\"   For real testing, use actual driving footage or public datasets.\")\n",
    "print(\"\\nGenerating test scenarios...\")\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Scenario: {scenario.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    img = create_pedestrian_scene(scenario)\n",
    "    detections = detect_pedestrians(img, conf_threshold=0.25)\n",
    "    \n",
    "    # Analyze\n",
    "    if scenario == 'normal' and len(detections) < 2:\n",
    "        print(\"   ‚ö†Ô∏è False negatives likely!\")\n",
    "    elif scenario == 'occluded' and len(detections) < 1:\n",
    "        print(\"   ‚ö†Ô∏è Failed to detect occluded pedestrians!\")\n",
    "    elif scenario == 'night' and len(detections) < 1:\n",
    "        print(\"   ‚ö†Ô∏è Poor performance in low light!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Failure Mode Analysis\n",
    "\n",
    "Let's systematically analyze when pedestrian detection fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common failure modes\n",
    "failure_modes = pd.DataFrame({\n",
    "    'Failure Mode': [\n",
    "        'Occlusion',\n",
    "        'Low Light / Night',\n",
    "        'Motion Blur',\n",
    "        'Small/Distant Objects',\n",
    "        'Unusual Poses',\n",
    "        'Weather (Rain/Fog)',\n",
    "        'Crowded Scenes',\n",
    "        'Non-standard Pedestrians'\n",
    "    ],\n",
    "    'Frequency': [30, 25, 15, 20, 10, 20, 15, 8],  # % of failures\n",
    "    'Severity': [9, 10, 7, 8, 6, 9, 7, 10],  # 1-10 scale\n",
    "    'Mitigation': [\n",
    "        'Multi-view fusion, temporal tracking',\n",
    "        'Thermal camera, LiDAR fusion',\n",
    "        'Higher frame rate, prediction',\n",
    "        'Higher resolution cameras, zoom',\n",
    "        'More diverse training data',\n",
    "        'Radar fusion, all-weather sensors',\n",
    "        'Tracking, crowd-specific models',\n",
    "        'Specialized training data'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(failure_modes)\n",
    "\n",
    "# Visualize failure modes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Frequency\n",
    "axes[0].barh(failure_modes['Failure Mode'], failure_modes['Frequency'],\n",
    "            color=plt.cm.Reds(np.linspace(0.3, 0.9, len(failure_modes))))\n",
    "axes[0].set_xlabel('Failure Frequency (%)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Pedestrian Detection Failure Modes', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "for i, (mode, freq) in enumerate(zip(failure_modes['Failure Mode'], failure_modes['Frequency'])):\n",
    "    axes[0].text(freq + 0.5, i, f\"{freq}%\", va='center', fontsize=9)\n",
    "\n",
    "# Severity vs Frequency\n",
    "scatter = axes[1].scatter(failure_modes['Frequency'], failure_modes['Severity'],\n",
    "                         s=300, alpha=0.6, c=range(len(failure_modes)), cmap='viridis')\n",
    "axes[1].set_xlabel('Failure Frequency (%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Severity (1-10)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Failure Mode Risk Assessment', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate high-risk quadrant\n",
    "axes[1].axhline(y=7, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].axvline(x=15, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].text(22, 9.5, 'High Risk\\n(Common + Severe)', \n",
    "            fontsize=11, color='red', fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Add labels\n",
    "for i, row in failure_modes.iterrows():\n",
    "    axes[1].annotate(row['Failure Mode'], \n",
    "                    (row['Frequency'], row['Severity']),\n",
    "                    fontsize=7, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüö® High-Risk Failure Modes (Common + Severe):\")\n",
    "high_risk = failure_modes[(failure_modes['Frequency'] > 15) & (failure_modes['Severity'] > 7)]\n",
    "for _, row in high_risk.iterrows():\n",
    "    print(f\"   - {row['Failure Mode']}: {row['Mitigation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ ISO 26262 Safety Requirements\n",
    "\n",
    "**ISO 26262** is the automotive functional safety standard.\n",
    "\n",
    "### ASIL Levels (Automotive Safety Integrity Level):\n",
    "- **ASIL QM:** No safety requirement\n",
    "- **ASIL A:** Lowest safety requirement\n",
    "- **ASIL B:** Medium\n",
    "- **ASIL C:** High\n",
    "- **ASIL D:** Highest (safety-critical, e.g., braking, steering, pedestrian detection)\n",
    "\n",
    "### Requirements for ASIL-D Pedestrian Detection:\n",
    "1. **Redundancy:** Multiple sensors (camera + LiDAR + radar)\n",
    "2. **Validation:** Extensive testing (millions of scenarios)\n",
    "3. **Fail-safe:** Degraded mode if sensor fails\n",
    "4. **Diagnostics:** Real-time sensor health monitoring\n",
    "5. **Documentation:** Complete traceability from requirements to code\n",
    "6. **Testing:** Hardware-in-the-loop (HIL), software-in-the-loop (SIL)\n",
    "7. **Performance:** <100ms latency, >99.9% detection rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISO 26262 ASIL determination\n",
    "# Based on: Severity, Exposure, Controllability\n",
    "\n",
    "asil_table = pd.DataFrame({\n",
    "    'Hazard': [\n",
    "        'Pedestrian collision (high speed)',\n",
    "        'Pedestrian collision (low speed)',\n",
    "        'False positive (unnecessary brake)',\n",
    "        'Delayed detection (>200ms)',\n",
    "        'Complete sensor failure'\n",
    "    ],\n",
    "    'Severity': ['S3 (Fatal)', 'S2 (Severe injury)', 'S1 (Light injury)', 'S3 (Fatal)', 'S3 (Fatal)'],\n",
    "    'Exposure': ['E4 (High)', 'E4 (High)', 'E3 (Medium)', 'E4 (High)', 'E2 (Low)'],\n",
    "    'Controllability': ['C3 (Uncontrollable)', 'C2 (Difficult)', 'C1 (Simple)', 'C3 (Uncontrollable)', 'C3 (Uncontrollable)'],\n",
    "    'ASIL': ['D', 'C', 'A', 'D', 'D']\n",
    "})\n",
    "\n",
    "display(asil_table)\n",
    "\n",
    "print(\"\\nüí° Key Takeaway:\")\n",
    "print(\"   - Pedestrian detection is ASIL-D (highest criticality)\")\n",
    "print(\"   - Failure can lead to FATAL consequences\")\n",
    "print(\"   - Requires extensive validation and redundancy\")\n",
    "print(\"\\nüîó ISO 26262 mandates:\")\n",
    "print(\"   - Sensor fusion (camera + LiDAR + radar)\")\n",
    "print(\"   - Real-time diagnostics\")\n",
    "print(\"   - Fail-operational or fail-safe design\")\n",
    "print(\"   - Extensive testing (>100M miles)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Performance Metrics for Safety\n",
    "\n",
    "For safety-critical applications, we care about more than just accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define safety-critical metrics\n",
    "safety_metrics = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Recall (Detection Rate)',\n",
    "        'Precision',\n",
    "        'Latency',\n",
    "        'False Negative Rate',\n",
    "        'False Positive Rate',\n",
    "        'Temporal Consistency',\n",
    "        'Distance Detection Range',\n",
    "        'Robustness (Edge Cases)'\n",
    "    ],\n",
    "    'Safety Requirement': [\n",
    "        '>99.9%',\n",
    "        '>95%',\n",
    "        '<100ms',\n",
    "        '<0.1%',\n",
    "        '<5%',\n",
    "        '>98% (frame-to-frame)',\n",
    "        '>100m',\n",
    "        '>90% (on long-tail scenarios)'\n",
    "    ],\n",
    "    'Why Critical': [\n",
    "        'Missing pedestrian ‚Üí collision',\n",
    "        'Too many false alarms ‚Üí driver distrust',\n",
    "        'Late detection ‚Üí no time to brake',\n",
    "        'Direct safety impact',\n",
    "        'Comfort & trust issue',\n",
    "        'Tracking failures cause confusion',\n",
    "        'Braking distance at highway speeds',\n",
    "        'Real world has edge cases'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(safety_metrics)\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Trade-offs:\")\n",
    "print(\"   - Higher recall (detect more) ‚Üí More false positives\")\n",
    "print(\"   - Lower latency ‚Üí May sacrifice accuracy\")\n",
    "print(\"   - Longer range ‚Üí Lower resolution, harder detection\")\n",
    "print(\"\\nüí° Safety-first approach: Prioritize RECALL over precision\")\n",
    "print(\"   Better to brake unnecessarily than miss a pedestrian!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Visualize Precision-Recall Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate precision-recall curve\n",
    "confidence_thresholds = np.linspace(0.1, 0.9, 20)\n",
    "\n",
    "# Simulated data (in practice, computed from validation set)\n",
    "recall = 1 - (confidence_thresholds - 0.1) / 0.8  # Higher threshold ‚Üí lower recall\n",
    "precision = 0.5 + 0.4 * (confidence_thresholds - 0.1) / 0.8  # Higher threshold ‚Üí higher precision\n",
    "\n",
    "# F1 score\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Precision-Recall curve\n",
    "axes[0].plot(recall, precision, 'b-', linewidth=3, label='Detection Model')\n",
    "axes[0].scatter(recall, precision, c=confidence_thresholds, cmap='viridis', s=100, zorder=5)\n",
    "axes[0].axhline(y=0.95, color='green', linestyle='--', label='Precision Target (95%)', linewidth=2)\n",
    "axes[0].axvline(x=0.999, color='red', linestyle='--', label='Recall Target (99.9%)', linewidth=2)\n",
    "axes[0].set_xlabel('Recall (Detection Rate)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Precision-Recall Trade-off', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].set_xlim(0.6, 1.0)\n",
    "axes[0].set_ylim(0.4, 1.0)\n",
    "\n",
    "# Add operating point\n",
    "optimal_idx = np.argmax(f1)\n",
    "axes[0].scatter(recall[optimal_idx], precision[optimal_idx], \n",
    "               s=300, c='red', marker='*', zorder=10, \n",
    "               label=f'Optimal (F1={f1[optimal_idx]:.3f})')\n",
    "\n",
    "# Metrics vs threshold\n",
    "axes[1].plot(confidence_thresholds, recall, 'b-', linewidth=2, label='Recall', marker='o')\n",
    "axes[1].plot(confidence_thresholds, precision, 'g-', linewidth=2, label='Precision', marker='s')\n",
    "axes[1].plot(confidence_thresholds, f1, 'r-', linewidth=2, label='F1-Score', marker='^')\n",
    "axes[1].axhline(y=0.999, color='red', linestyle='--', alpha=0.5, label='Safety Target (99.9%)')\n",
    "axes[1].set_xlabel('Confidence Threshold', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Metrics vs. Confidence Threshold', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].set_ylim(0.4, 1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° For safety-critical systems:\")\n",
    "print(\"   - Choose LOW confidence threshold to maximize recall\")\n",
    "print(\"   - Accept some false positives (better safe than sorry)\")\n",
    "print(\"   - Use sensor fusion to reduce false positives\")\n",
    "print(f\"\\n   Optimal threshold for max F1: {confidence_thresholds[optimal_idx]:.2f}\")\n",
    "print(f\"   But for safety, use lower threshold (~{confidence_thresholds[2]:.2f}) to ensure 99.9% recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úèÔ∏è Exercise: Safety Analysis\n",
    "\n",
    "**Scenario:** You deployed a pedestrian detection system. After 1 million frames of testing:\n",
    "- Total pedestrians: 50,000\n",
    "- True Positives: 49,500\n",
    "- False Positives: 1,000\n",
    "- False Negatives: 500\n",
    "\n",
    "**Questions:**\n",
    "1. Calculate precision and recall\n",
    "2. Is this system safe for ASIL-D?\n",
    "3. What's the estimated risk?\n",
    "4. What improvements would you recommend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate metrics and assess safety\n",
    "\n",
    "# Given data\n",
    "true_positives = 49500\n",
    "false_positives = 1000\n",
    "false_negatives = 500\n",
    "total_pedestrians = 50000\n",
    "\n",
    "# Calculate metrics\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "false_negative_rate = false_negatives / total_pedestrians\n",
    "\n",
    "print(\"üìä System Performance:\")\n",
    "print(f\"   Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"   Recall: {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"   F1-Score: {f1_score:.4f}\")\n",
    "print(f\"   False Negative Rate: {false_negative_rate:.4f} ({false_negative_rate*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Safety Assessment:\")\n",
    "if recall >= 0.999:\n",
    "    print(\"   ‚úÖ Meets ASIL-D recall requirement (>99.9%)\")\n",
    "else:\n",
    "    print(f\"   ‚ùå FAILS ASIL-D requirement! (Recall: {recall*100:.2f}%, Need: >99.9%)\")\n",
    "    print(f\"   ‚ùå Missing {false_negatives} pedestrians per 1M frames is UNACCEPTABLE\")\n",
    "\n",
    "if precision >= 0.95:\n",
    "    print(\"   ‚úÖ Meets precision requirement (>95%)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Precision below target ({precision*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nüö® Risk Estimation:\")\n",
    "print(f\"   - If vehicle drives at 30 fps video: {false_negatives * 30 / 1_000_000:.1f} missed pedestrians/sec\")\n",
    "print(f\"   - At 50 km/h: ~14 m/s ‚Üí {false_negatives * 14 / 1_000_000:.2f}m driven while missing pedestrian\")\n",
    "print(f\"   - Risk: Collision if pedestrian within this distance\")\n",
    "\n",
    "print(\"\\nüí° Recommended Improvements:\")\n",
    "print(\"   1. Lower confidence threshold to increase recall\")\n",
    "print(\"   2. Add LiDAR/radar fusion for redundancy\")\n",
    "print(\"   3. Collect more training data for edge cases\")\n",
    "print(\"   4. Implement temporal tracking (reduce single-frame misses)\")\n",
    "print(\"   5. Add fail-safe mechanisms (emergency braking)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "### Pedestrian Detection is Safety-Critical\n",
    "- **ASIL-D classification** - highest automotive safety level\n",
    "- **65%+ fatalities** occur in low-light conditions\n",
    "- **Vulnerable road users** - no protection, unpredictable behavior\n",
    "\n",
    "### Common Failure Modes\n",
    "1. **Occlusion** - partially hidden pedestrians\n",
    "2. **Low light / Night** - poor visibility\n",
    "3. **Small/distant objects** - insufficient resolution\n",
    "4. **Unusual poses** - outside training distribution\n",
    "5. **Weather** - rain, fog degrade camera performance\n",
    "\n",
    "### ISO 26262 Requirements\n",
    "- **Redundancy:** Multiple sensors (camera + LiDAR + radar)\n",
    "- **Performance:** >99.9% recall, <100ms latency\n",
    "- **Validation:** Extensive testing (millions of scenarios)\n",
    "- **Fail-safe:** Degraded mode if sensor fails\n",
    "- **Documentation:** Complete traceability\n",
    "\n",
    "### Safety-First Metrics\n",
    "- **Prioritize RECALL** over precision (better to brake unnecessarily)\n",
    "- **False negatives = potential collisions** (CRITICAL)\n",
    "- **False positives = comfort issue** (annoying but not dangerous)\n",
    "- **Temporal consistency** - track across frames\n",
    "\n",
    "### Mitigation Strategies\n",
    "1. **Sensor fusion** - combine camera + LiDAR + radar\n",
    "2. **Lower confidence threshold** - detect more (accept some false positives)\n",
    "3. **Temporal tracking** - smooth detections across frames\n",
    "4. **Diverse training data** - include edge cases\n",
    "5. **Thermal cameras** - for night/low-light\n",
    "6. **Fail-safe mechanisms** - automatic emergency braking\n",
    "\n",
    "### Real-World Lessons\n",
    "- **Uber ATG (2018):** Classifier confusion + disabled emergency braking ‚Üí FATAL\n",
    "- **Tesla crashes:** Over-reliance on camera in low light\n",
    "- **Industry standard:** Multi-sensor fusion is MANDATORY for Level 4+\n",
    "\n",
    "---\n",
    "\n",
    "## üîú Next Steps: Session 2\n",
    "\n",
    "**Session 1 Complete!** You've learned:\n",
    "- ‚úÖ SAE automation levels and AV architecture\n",
    "- ‚úÖ Sensor modalities and fusion\n",
    "- ‚úÖ Object detection with deep learning\n",
    "- ‚úÖ Datasets and their limitations\n",
    "- ‚úÖ Pedestrian detection as safety-critical task\n",
    "\n",
    "**Session 2 Preview:** AI Safety Failures & Adversarial Attacks\n",
    "- Real accident case studies (Uber, Tesla, Cruise)\n",
    "- Adversarial examples (physical patches that fool detectors)\n",
    "- Out-of-distribution detection\n",
    "- Uncertainty quantification\n",
    "- Safety validation techniques\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ó Interactive Demo\n",
    "\n",
    "**Try YOLOv8 yourself:**\n",
    "\n",
    "üîó [Hugging Face YOLOv8 Demo](https://huggingface.co/spaces/valid999/Yolov8_object_detection)\n",
    "\n",
    "**Exercise:**\n",
    "1. Upload challenging pedestrian images:\n",
    "   - Night scenes\n",
    "   - Crowded streets\n",
    "   - Unusual poses\n",
    "   - Partial occlusions\n",
    "2. Analyze failure cases\n",
    "3. Think about mitigation strategies\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook created by Milin Patel | Hochschule Kempten*  \n",
    "*Last updated: 2025-01-17*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
