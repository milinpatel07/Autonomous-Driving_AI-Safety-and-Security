{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 8: Out-of-Distribution (OOD) Detection\n",
    "\n",
    "**Session 2: Failure Modes and Edge Cases**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/milinpatel07/Autonomous-Driving_AI-Safety-and-Security/blob/main/AV_Perception_Safety_Workshop/Session_2_Failure_Modes_and_Edge_Cases/notebooks/08_OOD_Detection.ipynb)\n",
    "\n",
    "**Author:** Milin Patel  \n",
    "**Duration:** ~25 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- âœ… Understand the out-of-distribution (OOD) problem\n",
    "- âœ… Implement Mahalanobis distance-based OOD detection\n",
    "- âœ… Apply energy-based OOD detection\n",
    "- âœ… Use Monte Carlo Dropout for uncertainty estimation\n",
    "- âœ… Evaluate OOD detectors with AUROC and FPR@95\n",
    "- âœ… Connect OOD detection to ISO 21448 SOTIF\n",
    "- âœ… Design safety responses for OOD scenarios\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1ï¸âƒ£ The Out-of-Distribution Problem\n",
    "\n",
    "### What is OOD?\n",
    "\n",
    "**In-Distribution (ID):** Data similar to what the model was trained on  \n",
    "**Out-of-Distribution (OOD):** Data that differs significantly from training data\n",
    "\n",
    "### Examples in Autonomous Driving\n",
    "\n",
    "**In-Distribution:**\n",
    "- Cars, trucks, pedestrians, cyclists\n",
    "- Clear weather, paved roads\n",
    "- Standard traffic signs and markings\n",
    "\n",
    "**Out-of-Distribution:**\n",
    "- Unusual objects: Sofa on highway, escaped animals\n",
    "- Extreme weather: Sandstorm, heavy snow, flooding\n",
    "- Novel situations: Overturned truck, downed power lines\n",
    "- Sensor degradation: Dirty camera, misaligned LiDAR\n",
    "\n",
    "### Why OOD Detection Matters\n",
    "\n",
    "**Problem:** Neural networks are **overconfident** on OOD inputs\n",
    "- Model trained on cats/dogs may classify a horse as \"dog\" with 95% confidence\n",
    "- AV model trained on clear weather may misclassify in heavy fog with high confidence\n",
    "\n",
    "**Danger for AVs:**\n",
    "- High confidence â‰  correctness\n",
    "- System doesn't know what it doesn't know\n",
    "- Can lead to catastrophic failures\n",
    "\n",
    "**Solution:** OOD detection identifies when input is outside training distribution\n",
    "- Flag uncertain situations\n",
    "- Trigger safety response (slow down, hand over to driver, stop)\n",
    "\n",
    "### Connection to ISO 21448 SOTIF\n",
    "\n",
    "**SOTIF (Safety Of The Intended Functionality):**\n",
    "- Addresses failures even when system works as designed\n",
    "- Focus on **known and unknown unsafe scenarios**\n",
    "- OOD detection helps identify **unknown unsafe scenarios**\n",
    "\n",
    "**SOTIF Requirement:** System must detect when it's operating outside its ODD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ID vs OOD concept\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "# In-distribution: centered at (2, 2)\n",
    "id_data = np.random.multivariate_normal([2, 2], [[1, 0.5], [0.5, 1]], 200)\n",
    "# Out-of-distribution: far from ID data\n",
    "ood_data = np.random.multivariate_normal([6, 6], [[0.5, 0], [0, 0.5]], 50)\n",
    "\n",
    "# Plot 1: Feature space\n",
    "axes[0].scatter(id_data[:, 0], id_data[:, 1], c='green', alpha=0.6, s=50, label='In-Distribution')\n",
    "axes[0].scatter(ood_data[:, 0], ood_data[:, 1], c='red', alpha=0.6, s=50, label='Out-of-Distribution')\n",
    "axes[0].set_xlabel('Feature 1', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Feature 2', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Feature Space: ID vs OOD', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Draw boundary\n",
    "from matplotlib.patches import Ellipse\n",
    "ellipse = Ellipse(xy=(2, 2), width=4, height=4, angle=45, \n",
    "                  facecolor='none', edgecolor='blue', linewidth=3, linestyle='--', label='ID Boundary')\n",
    "axes[0].add_patch(ellipse)\n",
    "\n",
    "# Plot 2: Confidence distribution\n",
    "id_confidence = np.random.beta(8, 2, 200)  # High confidence for ID\n",
    "ood_confidence = np.random.beta(5, 3, 50)  # Should be lower but often isn't!\n",
    "\n",
    "axes[1].hist(id_confidence, bins=20, alpha=0.6, color='green', label='ID Confidence')\n",
    "axes[1].hist(ood_confidence, bins=20, alpha=0.6, color='red', label='OOD Confidence (Problem!)')\n",
    "axes[1].axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Threshold')\n",
    "axes[1].set_xlabel('Model Confidence', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Overconfidence Problem', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âš ï¸ Problem: OOD data often receives high confidence scores!\")\n",
    "print(\"   Solution: OOD detection methods beyond softmax confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2ï¸âƒ£ Load Pre-trained Model and Data\n",
    "\n",
    "We'll use CIFAR-10 as in-distribution and SVHN as out-of-distribution for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18 on CIFAR-10 (or train quickly)\n",
    "print(\"Loading model...\")\n",
    "\n",
    "# Define simple ResNet for CIFAR-10\n",
    "class SimpleCIFAR10Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCIFAR10Net, self).__init__()\n",
    "        self.model = resnet18(pretrained=False, num_classes=10)\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def forward_features(self, x):\n",
    "        \"\"\"Return intermediate features for OOD detection\"\"\"\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        x = self.model.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "model = SimpleCIFAR10Net().to(device)\n",
    "\n",
    "print(\"âœ… Model loaded (for demo purposes, assume pre-trained)\")\n",
    "print(\"   In production, you'd train on your specific AV dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# In-distribution: CIFAR-10\n",
    "id_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "id_loader = torch.utils.data.DataLoader(id_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Out-of-distribution: SVHN (street house numbers)\n",
    "ood_dataset = torchvision.datasets.SVHN(root='./data', split='test', download=True, transform=transform)\n",
    "ood_loader = torch.utils.data.DataLoader(ood_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"âœ… Datasets loaded:\")\n",
    "print(f\"   ID (CIFAR-10): {len(id_dataset)} images\")\n",
    "print(f\"   OOD (SVHN): {len(ood_dataset)} images\")\n",
    "\n",
    "# Show examples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(id_dataset[i][0].permute(1, 2, 0) * 0.5 + 0.5)\n",
    "    axes[0, i].set_title(f'ID: {id_dataset.classes[id_dataset[i][1]]}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(ood_dataset[i][0].permute(1, 2, 0) * 0.5 + 0.5)\n",
    "    axes[1, i].set_title(f'OOD: SVHN', fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "fig.suptitle('In-Distribution (CIFAR-10) vs Out-of-Distribution (SVHN)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3ï¸âƒ£ Method 1: Maximum Softmax Probability (Baseline)\n",
    "\n",
    "**Idea:** Use maximum softmax probability as OOD score\n",
    "- High probability â†’ In-distribution\n",
    "- Low probability â†’ Out-of-distribution\n",
    "\n",
    "**Problem:** As we'll see, this often fails!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute softmax scores\n",
    "def compute_softmax_scores(model, loader, device):\n",
    "    \"\"\"Compute maximum softmax probability for each sample\"\"\"\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            max_probs, _ = torch.max(probs, dim=1)\n",
    "            scores.extend(max_probs.cpu().numpy())\n",
    "    \n",
    "    return np.array(scores)\n",
    "\n",
    "print(\"Computing Maximum Softmax Probability scores...\")\n",
    "id_softmax_scores = compute_softmax_scores(model, id_loader, device)\n",
    "ood_softmax_scores = compute_softmax_scores(model, ood_loader, device)\n",
    "\n",
    "print(f\"âœ… Scores computed:\")\n",
    "print(f\"   ID mean: {id_softmax_scores.mean():.3f} Â± {id_softmax_scores.std():.3f}\")\n",
    "print(f\"   OOD mean: {ood_softmax_scores.mean():.3f} Â± {ood_softmax_scores.std():.3f}\")\n",
    "\n",
    "# Visualize distributions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(id_softmax_scores, bins=50, alpha=0.6, color='green', label='ID', density=True)\n",
    "plt.hist(ood_softmax_scores, bins=50, alpha=0.6, color='red', label='OOD', density=True)\n",
    "plt.xlabel('Maximum Softmax Probability', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Density', fontsize=12, fontweight='bold')\n",
    "plt.title('Baseline: Maximum Softmax Probability', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâš ï¸ Notice: Significant overlap! OOD samples still get high confidence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4ï¸âƒ£ Method 2: Mahalanobis Distance-Based Detection\n",
    "\n",
    "**Idea:** Measure distance in feature space using Mahalanobis distance\n",
    "\n",
    "**Mahalanobis Distance:**\n",
    "$$D_M(x) = \\sqrt{(x - \\mu)^T \\Sigma^{-1} (x - \\mu)}$$\n",
    "\n",
    "Where:\n",
    "- $\\mu$ = mean of ID features\n",
    "- $\\Sigma$ = covariance matrix of ID features\n",
    "\n",
    "**Intuition:** How far is this sample from the typical ID distribution?\n",
    "\n",
    "**Reference:** Lee et al. (2018) - \"A Simple Unified Framework for Detecting OOD Examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from ID training data\n",
    "def extract_features(model, loader, device, max_samples=1000):\n",
    "    \"\"\"Extract penultimate layer features\"\"\"\n",
    "    model.eval()\n",
    "    features = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(loader):\n",
    "            if i * loader.batch_size >= max_samples:\n",
    "                break\n",
    "            images = images.to(device)\n",
    "            feats = model.forward_features(images)\n",
    "            features.append(feats.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(features, axis=0)\n",
    "\n",
    "print(\"Extracting features from ID data...\")\n",
    "id_train_features = extract_features(model, id_loader, device, max_samples=2000)\n",
    "\n",
    "# Fit Gaussian distribution\n",
    "mean = np.mean(id_train_features, axis=0)\n",
    "cov = EmpiricalCovariance().fit(id_train_features)\n",
    "\n",
    "print(f\"âœ… Fitted Gaussian:\")\n",
    "print(f\"   Feature dimension: {mean.shape[0]}\")\n",
    "print(f\"   Number of samples: {id_train_features.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Mahalanobis distance scores\n",
    "def compute_mahalanobis_scores(model, loader, device, mean, cov):\n",
    "    \"\"\"Compute Mahalanobis distance for each sample\"\"\"\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            features = model.forward_features(images).cpu().numpy()\n",
    "            \n",
    "            for feat in features:\n",
    "                score = mahalanobis(feat, mean, cov.precision_)\n",
    "                scores.append(score)\n",
    "    \n",
    "    return np.array(scores)\n",
    "\n",
    "print(\"Computing Mahalanobis distance scores...\")\n",
    "id_mahal_scores = compute_mahalanobis_scores(model, id_loader, device, mean, cov)\n",
    "ood_mahal_scores = compute_mahalanobis_scores(model, ood_loader, device, mean, cov)\n",
    "\n",
    "print(f\"âœ… Scores computed:\")\n",
    "print(f\"   ID mean: {id_mahal_scores.mean():.3f} Â± {id_mahal_scores.std():.3f}\")\n",
    "print(f\"   OOD mean: {ood_mahal_scores.mean():.3f} Â± {ood_mahal_scores.std():.3f}\")\n",
    "\n",
    "# Visualize distributions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(id_mahal_scores, bins=50, alpha=0.6, color='green', label='ID', density=True)\n",
    "plt.hist(ood_mahal_scores, bins=50, alpha=0.6, color='red', label='OOD', density=True)\n",
    "plt.xlabel('Mahalanobis Distance', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Density', fontsize=12, fontweight='bold')\n",
    "plt.title('Mahalanobis Distance-Based OOD Detection', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Better separation! OOD samples have higher distance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5ï¸âƒ£ Method 3: Energy-Based Detection\n",
    "\n",
    "**Idea:** Use energy function instead of softmax\n",
    "\n",
    "**Energy:**\n",
    "$$E(x) = -\\log \\sum_{i=1}^{C} e^{f_i(x)}$$\n",
    "\n",
    "Where $f_i(x)$ is the logit for class $i$.\n",
    "\n",
    "**Intuition:** \n",
    "- ID samples: Low energy (model is confident)\n",
    "- OOD samples: High energy (model is uncertain)\n",
    "\n",
    "**Reference:** Liu et al. (2020) - \"Energy-based Out-of-distribution Detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute energy scores\n",
    "def compute_energy_scores(model, loader, device, temperature=1.0):\n",
    "    \"\"\"Compute energy score for each sample\"\"\"\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            logits = model(images)\n",
    "            # Energy = -log(sum(exp(logits)))\n",
    "            energy = -temperature * torch.logsumexp(logits / temperature, dim=1)\n",
    "            scores.extend(energy.cpu().numpy())\n",
    "    \n",
    "    return np.array(scores)\n",
    "\n",
    "print(\"Computing Energy scores...\")\n",
    "id_energy_scores = compute_energy_scores(model, id_loader, device)\n",
    "ood_energy_scores = compute_energy_scores(model, ood_loader, device)\n",
    "\n",
    "print(f\"âœ… Scores computed:\")\n",
    "print(f\"   ID mean: {id_energy_scores.mean():.3f} Â± {id_energy_scores.std():.3f}\")\n",
    "print(f\"   OOD mean: {ood_energy_scores.mean():.3f} Â± {ood_energy_scores.std():.3f}\")\n",
    "\n",
    "# Visualize distributions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(id_energy_scores, bins=50, alpha=0.6, color='green', label='ID', density=True)\n",
    "plt.hist(ood_energy_scores, bins=50, alpha=0.6, color='red', label='OOD', density=True)\n",
    "plt.xlabel('Energy Score', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Density', fontsize=12, fontweight='bold')\n",
    "plt.title('Energy-Based OOD Detection', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Good separation! OOD samples have higher (less negative) energy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6ï¸âƒ£ Method 4: Monte Carlo Dropout Uncertainty\n",
    "\n",
    "**Idea:** Use dropout at inference time to estimate uncertainty\n",
    "\n",
    "**Procedure:**\n",
    "1. Keep dropout enabled during inference\n",
    "2. Run multiple forward passes (e.g., 30 times)\n",
    "3. Compute variance of predictions\n",
    "4. High variance â†’ High uncertainty â†’ Likely OOD\n",
    "\n",
    "**Advantages:**\n",
    "- No additional training required\n",
    "- Provides uncertainty estimates\n",
    "- Applicable to existing models\n",
    "\n",
    "**Reference:** Gal & Ghahramani (2016) - \"Dropout as a Bayesian Approximation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout to model (for demonstration)\n",
    "class ModelWithDropout(nn.Module):\n",
    "    def __init__(self, base_model, dropout_rate=0.3):\n",
    "        super(ModelWithDropout, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.base_model.forward_features(x)\n",
    "        features = self.dropout(features)  # Apply dropout\n",
    "        output = self.base_model.model.fc(features)\n",
    "        return output\n",
    "\n",
    "dropout_model = ModelWithDropout(model).to(device)\n",
    "\n",
    "def compute_mc_dropout_uncertainty(model, loader, device, num_samples=10):\n",
    "    \"\"\"Compute predictive uncertainty using MC Dropout\"\"\"\n",
    "    model.train()  # Keep dropout enabled\n",
    "    uncertainties = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Multiple forward passes\n",
    "            predictions = []\n",
    "            for _ in range(num_samples):\n",
    "                outputs = model(images)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                predictions.append(probs.cpu().numpy())\n",
    "            \n",
    "            # Stack predictions\n",
    "            predictions = np.stack(predictions, axis=0)  # Shape: [num_samples, batch, classes]\n",
    "            \n",
    "            # Compute variance (uncertainty)\n",
    "            variance = np.var(predictions, axis=0).max(axis=1)  # Max variance across classes\n",
    "            uncertainties.extend(variance)\n",
    "    \n",
    "    return np.array(uncertainties)\n",
    "\n",
    "print(\"Computing MC Dropout uncertainty (this may take a moment)...\")\n",
    "id_mc_uncertainty = compute_mc_dropout_uncertainty(dropout_model, id_loader, device, num_samples=10)\n",
    "ood_mc_uncertainty = compute_mc_dropout_uncertainty(dropout_model, ood_loader, device, num_samples=10)\n",
    "\n",
    "print(f\"âœ… Uncertainty computed:\")\n",
    "print(f\"   ID mean: {id_mc_uncertainty.mean():.4f} Â± {id_mc_uncertainty.std():.4f}\")\n",
    "print(f\"   OOD mean: {ood_mc_uncertainty.mean():.4f} Â± {ood_mc_uncertainty.std():.4f}\")\n",
    "\n",
    "# Visualize distributions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(id_mc_uncertainty, bins=50, alpha=0.6, color='green', label='ID', density=True)\n",
    "plt.hist(ood_mc_uncertainty, bins=50, alpha=0.6, color='red', label='OOD', density=True)\n",
    "plt.xlabel('MC Dropout Uncertainty (Variance)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Density', fontsize=12, fontweight='bold')\n",
    "plt.title('Monte Carlo Dropout Uncertainty', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… OOD samples show higher uncertainty!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7ï¸âƒ£ Evaluation: AUROC and FPR@95\n",
    "\n",
    "### Metrics for OOD Detection\n",
    "\n",
    "**AUROC (Area Under ROC Curve):**\n",
    "- Measures overall detection performance\n",
    "- 1.0 = perfect separation, 0.5 = random\n",
    "- **Target for safety-critical systems: > 0.95**\n",
    "\n",
    "**FPR@95 (False Positive Rate at 95% TPR):**\n",
    "- What % of ID samples are wrongly flagged as OOD?\n",
    "- Lower is better (fewer false alarms)\n",
    "- **Target: < 5%**\n",
    "\n",
    "**Why these metrics?**\n",
    "- AVs must detect OOD reliably (high TPR)\n",
    "- But minimize false alarms (low FPR) to avoid unnecessary interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_ood_detector(id_scores, ood_scores, higher_is_ood=True):\n",
    "    \"\"\"\n",
    "    Evaluate OOD detector using AUROC and FPR@95\n",
    "    \n",
    "    Args:\n",
    "        id_scores: Scores for in-distribution samples\n",
    "        ood_scores: Scores for out-of-distribution samples\n",
    "        higher_is_ood: If True, higher scores indicate OOD\n",
    "    \"\"\"\n",
    "    # Create labels\n",
    "    y_true = np.concatenate([np.zeros(len(id_scores)), np.ones(len(ood_scores))])\n",
    "    \n",
    "    # Create predictions\n",
    "    if higher_is_ood:\n",
    "        y_score = np.concatenate([id_scores, ood_scores])\n",
    "    else:\n",
    "        y_score = np.concatenate([-id_scores, -ood_scores])\n",
    "    \n",
    "    # Compute AUROC\n",
    "    auroc = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    # Compute FPR@95\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    fpr_at_95 = fpr[np.argmax(tpr >= 0.95)]\n",
    "    \n",
    "    return auroc, fpr_at_95, fpr, tpr\n",
    "\n",
    "# Evaluate all methods\n",
    "methods = {\n",
    "    'Maximum Softmax': (id_softmax_scores, ood_softmax_scores, False),  # Lower is OOD\n",
    "    'Mahalanobis Distance': (id_mahal_scores, ood_mahal_scores, True),\n",
    "    'Energy-Based': (id_energy_scores, ood_energy_scores, True),\n",
    "    'MC Dropout': (id_mc_uncertainty, ood_mc_uncertainty, True)\n",
    "}\n",
    "\n",
    "results = []\n",
    "roc_curves = {}\n",
    "\n",
    "for method_name, (id_sc, ood_sc, higher_ood) in methods.items():\n",
    "    auroc, fpr95, fpr, tpr = evaluate_ood_detector(id_sc, ood_sc, higher_ood)\n",
    "    results.append({\n",
    "        'Method': method_name,\n",
    "        'AUROC': auroc,\n",
    "        'FPR@95': fpr95\n",
    "    })\n",
    "    roc_curves[method_name] = (fpr, tpr)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.style.background_gradient(cmap='RdYlGn', subset=['AUROC']).format(precision=3))\n",
    "\n",
    "print(\"\\nðŸ“Š Performance Comparison:\")\n",
    "print(f\"   Best AUROC: {results_df.loc[results_df['AUROC'].idxmax(), 'Method']} ({results_df['AUROC'].max():.3f})\")\n",
    "print(f\"   Best FPR@95: {results_df.loc[results_df['FPR@95'].idxmin(), 'Method']} ({results_df['FPR@95'].min():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "for (method_name, (fpr, tpr)), color in zip(roc_curves.items(), colors):\n",
    "    auroc = results_df[results_df['Method'] == method_name]['AUROC'].values[0]\n",
    "    plt.plot(fpr, tpr, linewidth=2, color=color, label=f'{method_name} (AUROC={auroc:.3f})')\n",
    "\n",
    "# Diagonal line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random')\n",
    "\n",
    "# Mark TPR=0.95 point\n",
    "plt.axhline(y=0.95, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.text(0.7, 0.96, 'TPR = 0.95', fontsize=10)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.title('ROC Curves: OOD Detection Methods', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Interpretation:\")\n",
    "print(\"   - Curve closer to top-left = better performance\")\n",
    "print(\"   - Mahalanobis and Energy-based outperform baseline Softmax\")\n",
    "print(\"   - MC Dropout provides uncertainty with minimal changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8ï¸âƒ£ Safety Implications and ISO 21448 SOTIF\n",
    "\n",
    "### Connection to SOTIF\n",
    "\n",
    "**ISO 21448 SOTIF** addresses:\n",
    "1. **Known unsafe scenarios:** Identified during testing\n",
    "2. **Unknown unsafe scenarios:** Not yet identified\n",
    "\n",
    "**OOD Detection helps with:**\n",
    "- **Detecting unknown scenarios** at runtime\n",
    "- **Triggering safety responses** (MRC - Minimum Risk Condition)\n",
    "- **Expanding scenario coverage** by logging OOD cases\n",
    "\n",
    "### Safety Response Protocol\n",
    "\n",
    "When OOD is detected:\n",
    "\n",
    "1. **Alert driver** (Level 2/3) or **initiate fallback** (Level 4/5)\n",
    "2. **Reduce speed** gradually\n",
    "3. **Increase following distance**\n",
    "4. **Activate emergency lights** if pulling over\n",
    "5. **Log incident** for offline analysis\n",
    "6. **Do NOT** make aggressive maneuvers\n",
    "\n",
    "### Performance Requirements\n",
    "\n",
    "For safety-critical AV deployment:\n",
    "- **AUROC > 0.95:** Reliable detection\n",
    "- **FPR@95 < 0.05:** Minimize false alarms (< 5%)\n",
    "- **Latency < 100ms:** Real-time detection\n",
    "- **Robustness:** Works across weather, lighting, sensor degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety decision logic example\n",
    "def safety_decision(ood_score, threshold, speed_kmh):\n",
    "    \"\"\"\n",
    "    Make safety decision based on OOD score\n",
    "    \n",
    "    Args:\n",
    "        ood_score: OOD detection score (higher = more OOD)\n",
    "        threshold: OOD threshold\n",
    "        speed_kmh: Current speed in km/h\n",
    "    \n",
    "    Returns:\n",
    "        action: Safety action to take\n",
    "    \"\"\"\n",
    "    if ood_score < threshold * 0.7:\n",
    "        return \"NORMAL: Continue autonomous operation\"\n",
    "    elif ood_score < threshold:\n",
    "        return \"CAUTION: Reduce speed by 20%, increase following distance\"\n",
    "    elif ood_score < threshold * 1.5:\n",
    "        return \"WARNING: Reduce speed by 50%, alert driver/remote operator\"\n",
    "    else:\n",
    "        return \"CRITICAL: Initiate Minimum Risk Condition (pull over safely)\"\n",
    "\n",
    "# Example scenarios\n",
    "threshold = 50.0  # Example threshold\n",
    "scenarios = [\n",
    "    (20, \"Clear day, normal traffic\"),\n",
    "    (40, \"Light fog, slightly reduced visibility\"),\n",
    "    (55, \"Heavy fog, unusual object detected\"),\n",
    "    (85, \"Extreme weather, multiple unknown objects\")\n",
    "]\n",
    "\n",
    "print(\"Safety Decision Examples:\\n\" + \"=\"*70)\n",
    "for score, description in scenarios:\n",
    "    action = safety_decision(score, threshold, speed_kmh=50)\n",
    "    print(f\"\\nScenario: {description}\")\n",
    "    print(f\"OOD Score: {score:.1f}\")\n",
    "    print(f\"Action: {action}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ’¡ Graded response: Severity of action matches uncertainty level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœï¸ Exercise: Design OOD Detector\n",
    "\n",
    "**Task:** You're designing an OOD detector for a Level 4 campus shuttle.\n",
    "\n",
    "**In-Distribution Scenarios:**\n",
    "- Students walking, bicycles, campus buses\n",
    "- Paved roads, crosswalks, stop signs\n",
    "- Clear weather, daylight hours\n",
    "- Speed: 15-25 km/h\n",
    "\n",
    "**Questions:**\n",
    "1. What OOD scenarios might occur?\n",
    "2. Which OOD detection method would you choose and why?\n",
    "3. What AUROC and FPR@95 targets would you set?\n",
    "4. What safety response would you implement for OOD detection?\n",
    "5. How would you validate your OOD detector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete your design\n",
    "\n",
    "your_design = {\n",
    "    'ood_scenarios': [\n",
    "        # List potential OOD scenarios\n",
    "        # Example: \"Construction zone with barriers\"\n",
    "    ],\n",
    "    'chosen_method': '',  # e.g., \"Mahalanobis Distance + MC Dropout ensemble\"\n",
    "    'rationale': '',  # Why did you choose this method?\n",
    "    'auroc_target': 0.0,  # Your AUROC target\n",
    "    'fpr95_target': 0.0,  # Your FPR@95 target\n",
    "    'safety_response': '',  # What action when OOD detected?\n",
    "    'validation_plan': [\n",
    "        # How will you test the OOD detector?\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Your OOD Detector Design:\")\n",
    "print(f\"\\nChosen Method: {your_design['chosen_method']}\")\n",
    "print(f\"Rationale: {your_design['rationale']}\")\n",
    "print(f\"\\nPerformance Targets:\")\n",
    "print(f\"  AUROC: {your_design['auroc_target']}\")\n",
    "print(f\"  FPR@95: {your_design['fpr95_target']}\")\n",
    "print(f\"\\nSafety Response: {your_design['safety_response']}\")\n",
    "\n",
    "print(\"\\nðŸ¤” Reflection:\")\n",
    "print(\"   - How does this relate to ISO 21448 SOTIF?\")\n",
    "print(\"   - What are the trade-offs of your chosen method?\")\n",
    "print(\"   - How would you handle false positives?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Key Takeaways\n",
    "\n",
    "### The OOD Problem\n",
    "- **Neural networks are overconfident** on out-of-distribution inputs\n",
    "- **Danger:** High confidence doesn't mean correct prediction\n",
    "- **Solution:** OOD detection methods beyond softmax probability\n",
    "\n",
    "### OOD Detection Methods\n",
    "1. **Maximum Softmax (Baseline):** Simple but often fails\n",
    "2. **Mahalanobis Distance:** Measures distance in feature space (effective!)\n",
    "3. **Energy-Based:** Uses energy function (strong performance)\n",
    "4. **MC Dropout:** Estimates uncertainty (minimal model changes)\n",
    "\n",
    "### Evaluation Metrics\n",
    "- **AUROC:** Overall detection performance (target > 0.95)\n",
    "- **FPR@95:** False alarm rate (target < 0.05)\n",
    "\n",
    "### Safety Implications\n",
    "- **ISO 21448 SOTIF:** OOD detection addresses unknown unsafe scenarios\n",
    "- **Safety response:** Graded actions based on OOD score\n",
    "- **Requirements:** High AUROC, low FPR, real-time performance\n",
    "\n",
    "### Best Practices\n",
    "1. âœ… Use **multiple OOD methods** (ensemble)\n",
    "2. âœ… Set **conservative thresholds** (safety over efficiency)\n",
    "3. âœ… Implement **graded responses** (not binary)\n",
    "4. âœ… **Log all OOD detections** for offline analysis\n",
    "5. âœ… **Continuously update** training data with OOD discoveries\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”œ Next: Corner Cases and Edge Cases\n",
    "\n",
    "Now let's explore specific types of challenging scenarios in autonomous driving!\n",
    "\n",
    "**Ready?** Open `09_Corner_Cases_and_Edge_Cases.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook created by Milin Patel | Hochschule Kempten*  \n",
    "*Last updated: 2025-01-18*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
