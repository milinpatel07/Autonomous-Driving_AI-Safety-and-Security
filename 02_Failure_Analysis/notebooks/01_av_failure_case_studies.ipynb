{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "Copyright (c) 2025 Milin Patel\n",
    "Hochschule Kempten - University of Applied Sciences\n",
    "\n",
    "Autonomous Driving: AI Safety and Security Workshop\n",
    "This project is licensed under the MIT License.\n",
    "See LICENSE file in the root directory for full license text.\n",
    "-->\n",
    "\n",
    "*Copyright Â© 2025 Milin Patel. All Rights Reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 7: Real-World AV Failure Case Studies\n",
    "\n",
    "**Module 02: Failure Modes and Edge Cases**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/milinpatel07/Autonomous-Driving_AI-Safety-and-Security/blob/master/02_Failure_Analysis/notebooks/07_AV_Failure_Case_Studies.ipynb)\n",
    "\n",
    "**Author:** Milin Patel \n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- âœ… Understand the root causes of major AV accidents\n",
    "- âœ… Analyze the Uber ATG Tempe crash in detail\n",
    "- âœ… Learn failure taxonomy for perception systems\n",
    "- âœ… Apply root cause analysis frameworks\n",
    "- âœ… Extract safety lessons from real incidents\n",
    "- âœ… Connect failures to system design principles\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, Image as IPImage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Why Study AV Failures?\n",
    "\n",
    "### The Importance of Failure Analysis\n",
    "\n",
    "**\"Those who cannot remember the past are condemned to repeat it.\"** - George Santayana\n",
    "\n",
    "Studying real-world AV failures is critical because:\n",
    "\n",
    "1. **Learn from mistakes:** Understand what went wrong to prevent recurrence\n",
    "2. **Identify systematic issues:** Discover common failure patterns\n",
    "3. **Improve designs:** Inform better system architectures\n",
    "4. **Update standards:** Drive safety regulations and best practices\n",
    "5. **Calibrate expectations:** Understand current technology limitations\n",
    "\n",
    "### Historical Context\n",
    "\n",
    "Aviation safety improved dramatically through rigorous accident investigation:\n",
    "- **1950s:** ~40 fatal accidents per million flights\n",
    "- **2020s:** <1 fatal accident per 10 million flights\n",
    "\n",
    "**Key:** Mandatory reporting, independent investigation, industry-wide learning\n",
    "\n",
    "**Challenge for AVs:** Industry is nascent, less regulated, competitive pressures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize major AV incidents timeline\n",
    "av_incidents = pd.DataFrame({\n",
    "    'Date': ['2016-05-07', '2016-07-01', '2018-03-18', '2018-03-23', '2019-12-29', '2021-08-16', '2023-10-02'],\n",
    "    'Company': ['Tesla', 'Tesla', 'Uber ATG', 'Tesla', 'Tesla', 'Tesla', 'Cruise'],\n",
    "    'Location': ['Florida, USA', 'Pennsylvania, USA', 'Tempe, AZ', 'Mountain View, CA', 'Indiana, USA', 'Texas, USA', 'San Francisco, CA'],\n",
    "    'Fatality': [True, True, True, True, False, True, False],\n",
    "    'Description': [\n",
    "        'Autopilot failed to detect white truck against bright sky',\n",
    "        'Autopilot collision with truck',\n",
    "        'Pedestrian struck and killed crossing street',\n",
    "        'Autopilot crash into highway barrier',\n",
    "        'Autopilot collision with parked fire truck',\n",
    "        'Autopilot crash with no driver present',\n",
    "        'Pedestrian dragged after being hit by human driver'\n",
    "    ],\n",
    "    'SAE_Level': [2, 2, 4, 2, 2, 2, 4],\n",
    "    'Primary_Cause': [\n",
    "        'Perception failure (camera)',\n",
    "        'Perception failure (camera)',\n",
    "        'Perception + safety driver inattention',\n",
    "        'Perception + driver inattention',\n",
    "        'Perception failure',\n",
    "        'Misuse (no driver)',\n",
    "        'Decision-making failure'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Convert date to datetime\n",
    "av_incidents['Date'] = pd.to_datetime(av_incidents['Date'])\n",
    "\n",
    "# Display table\n",
    "display(av_incidents[['Date', 'Company', 'Location', 'Fatality', 'SAE_Level']])\n",
    "\n",
    "print(\"\\nâš ï¸ Key Observation: Multiple perception failures across different companies!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize incidents timeline\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "# Plot incidents\n",
    "for idx, row in av_incidents.iterrows():\n",
    "    color = 'red' if row['Fatality'] else 'orange'\n",
    "    marker = 'X' if row['Fatality'] else 'o'\n",
    "    size = 300 if row['Fatality'] else 150\n",
    "    \n",
    "    ax.scatter(row['Date'], row['SAE_Level'], c=color, marker=marker, s=size, \n",
    "               alpha=0.7, edgecolors='black', linewidth=2, label=row['Company'] if idx < 2 else '')\n",
    "    \n",
    "    # Add label\n",
    "    ax.text(row['Date'], row['SAE_Level'] + 0.15, row['Company'], \n",
    "            ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Date', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('SAE Automation Level', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Timeline of Major Autonomous Vehicle Incidents (2016-2023)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "ax.set_yticks([0, 1, 2, 3, 4, 5])\n",
    "ax.set_ylim(-0.5, 5.5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='X', color='w', markerfacecolor='red', markersize=12, label='Fatal'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='orange', markersize=10, label='Non-fatal')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Notice: Incidents occur at both Level 2 (driver assistance) and Level 4 (high automation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study 1: Uber ATG Tempe Crash (2018)\n",
    "\n",
    "### Incident Overview\n",
    "\n",
    "**Date:** March 18, 2018, 9:58 PM \n",
    "**Location:** Tempe, Arizona, USA \n",
    "**Vehicle:** Volvo XC90 with Uber Advanced Technologies Group (ATG) self-driving system \n",
    "**SAE Level:** 4 (High Automation) - testing with safety driver \n",
    "**Outcome:** Pedestrian fatality (Elaine Herzberg, 49 years old)\n",
    "\n",
    "**First pedestrian fatality involving an autonomous vehicle in the United States.**\n",
    "\n",
    "### What Happened?\n",
    "\n",
    "1. **Pedestrian:** Walking bicycle across multi-lane road at night (not at crosswalk)\n",
    "2. **Vehicle:** Traveling at 39 mph in 35 mph zone, autonomous mode engaged\n",
    "3. **Detection:** System detected pedestrian 5.6 seconds before impact\n",
    "4. **Classification failures:** System fluctuated between \"vehicle,\" \"bicycle,\" \"unknown\"\n",
    "5. **No braking:** Emergency braking was disabled during autonomous operation\n",
    "6. **Safety driver:** Looking at phone, did not intervene until after impact\n",
    "7. **Impact:** Vehicle struck pedestrian, who died from injuries\n",
    "\n",
    "### NTSB Investigation Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeline of Uber crash detection and classification\n",
    "uber_timeline = pd.DataFrame({\n",
    "    'Time_Before_Impact': [5.6, 5.0, 4.5, 4.0, 3.5, 3.0, 2.5, 2.0, 1.5, 1.2, 0.0],\n",
    "    'Classification': ['Unknown', 'Vehicle', 'Unknown', 'Bicycle', 'Unknown', 'Bicycle', \n",
    "                      'Bicycle', 'Bicycle', 'Bicycle', 'Bicycle', 'Impact'],\n",
    "    'Action_Required': ['Monitor', 'Monitor', 'Monitor', 'Monitor', 'Monitor', 'Alert',\n",
    "                       'Brake', 'Hard brake', 'Hard brake', 'Emergency brake', 'Too late']\n",
    "})\n",
    "\n",
    "display(uber_timeline)\n",
    "\n",
    "print(\"\\nðŸš¨ Critical Issue: Classification uncertainty delayed decision-making!\")\n",
    "print(\"   System reset path prediction with each classification change.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize detection timeline\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Classification over time\n",
    "time_points = uber_timeline['Time_Before_Impact'].values\n",
    "classifications = uber_timeline['Classification'].values\n",
    "\n",
    "# Map classifications to numeric values for plotting\n",
    "class_map = {'Unknown': 0, 'Vehicle': 1, 'Bicycle': 2, 'Impact': 3}\n",
    "class_numeric = [class_map[c] for c in classifications]\n",
    "\n",
    "ax1.plot(time_points, class_numeric, marker='o', markersize=10, linewidth=2, color='darkblue')\n",
    "ax1.set_xlabel('Time Before Impact (seconds)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Classification', fontsize=12, fontweight='bold')\n",
    "ax1.set_yticks([0, 1, 2, 3])\n",
    "ax1.set_yticklabels(['Unknown', 'Vehicle', 'Bicycle', 'Impact'])\n",
    "ax1.set_title('Uber ATG System Classification Over Time', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axvspan(1.2, 5.6, alpha=0.2, color='red', label='Should have braked')\n",
    "ax1.legend()\n",
    "ax1.invert_xaxis()\n",
    "\n",
    "# Required action over time\n",
    "actions = uber_timeline['Action_Required'].values\n",
    "action_colors = ['green', 'green', 'green', 'green', 'green', 'yellow', \n",
    "                'orange', 'red', 'red', 'darkred', 'black']\n",
    "\n",
    "ax2.scatter(time_points, range(len(time_points)), c=action_colors, s=200, alpha=0.7)\n",
    "for i, (t, action) in enumerate(zip(time_points, actions)):\n",
    "    ax2.text(t, i, action, ha='right', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax2.set_xlabel('Time Before Impact (seconds)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Timeline', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Required Actions Timeline', fontsize=14, fontweight='bold')\n",
    "ax2.set_yticks([])\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "ax2.invert_xaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Insight: System had 5.6 seconds to react but classification uncertainty prevented timely action!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Causes (NTSB Findings)\n\n**1. Perception System Failures:**\n- âŒ Object classification instability (unknown â†’ vehicle â†’ bicycle)\n- âŒ Pedestrian crossing mid-block not in expected \"crosswalk\" scenario\n- âŒ System reset trajectory prediction with each classification change\n- âŒ Inadequate testing of jaywalking scenarios\n\n**2. System Design Issues:**\n- âŒ Emergency braking **disabled** during autonomous mode\n- âŒ Reliance on safety driver for emergency intervention (but no monitoring)\n- âŒ No redundant safety systems\n- âŒ Insufficient sensor coverage for low-light conditions\n\n**3. Organizational/Human Factors:**\n- âŒ Safety driver looking at phone (streaming video)\n- âŒ Inadequate safety driver monitoring systems\n- âŒ Pressure to reduce interventions (\"disengagements\")\n- âŒ Insufficient safety culture and oversight\n\n**4. Regulatory Gaps:**\n- âŒ No federal safety standards for autonomous vehicles\n- âŒ Limited state-level oversight\n- âŒ No mandatory incident reporting\n\n### Lessons Learned\n\n**Design Principles:**\n1. **Never disable safety-critical functions** (e.g., emergency braking)\n2. **Redundancy:** Multiple independent safety layers\n3. **Graceful degradation:** Fail safely when uncertain\n4. **Test edge cases:** Jaywalking, unexpected pedestrian behavior\n\n**Organizational:**\n1. **Safety culture:** Prioritize safety over development speed\n2. **Monitor safety drivers:** Ensure attention and readiness\n3. **Transparent reporting:** Share learnings across industry\n\n**Technical:**\n1. **Stable classification:** Don't reset decision-making with each class change\n2. **Conservative behavior:** Slow down when uncertain\n3. **Multi-modal sensing:** Camera + LiDAR + radar fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study 2: Tesla Autopilot Incidents\n",
    "\n",
    "### Florida Crash (May 2016) - First Fatal Autopilot Crash\n",
    "\n",
    "**Scenario:** Tesla Model S on highway, Autopilot engaged \n",
    "**Obstacle:** Tractor-trailer turning left across highway \n",
    "**Condition:** Bright sunlight, white truck against bright sky \n",
    "**Outcome:** Vehicle drove under truck, driver fatality\n",
    "\n",
    "**Root Cause:**\n",
    "- Camera-based perception failed to detect white truck against bright sky (high contrast)\n",
    "- Radar detected truck but classified as overhead sign (false positive mitigation)\n",
    "- Driver over-reliance on Autopilot (watching movie)\n",
    "\n",
    "**Technical Issue:** Camera saturation + sensor fusion logic error\n",
    "\n",
    "### Mountain View Crash (March 2018)\n",
    "\n",
    "**Scenario:** Tesla Model X on Highway 101, Autopilot engaged \n",
    "**Obstacle:** Concrete highway barrier (lane divider) \n",
    "**Condition:** Daylight, clear weather, damaged lane markings \n",
    "**Outcome:** Vehicle accelerated into barrier, driver fatality\n",
    "\n",
    "**Root Cause:**\n",
    "- Lane-keeping system followed faded/damaged lane markings\n",
    "- Driver distracted (playing mobile game)\n",
    "- System did not detect barrier as obstacle\n",
    "\n",
    "**Technical Issue:** Over-reliance on lane markings, insufficient object detection\n",
    "\n",
    "### Common Patterns Across Tesla Incidents\n",
    "\n",
    "1. **Perception limitations:**\n",
    " - Camera-only system vulnerable to lighting conditions\n",
    " - Difficulty detecting stationary objects (trucks, barriers)\n",
    " - Lane marking dependency\n",
    "\n",
    "2. **Human factors:**\n",
    " - Driver misunderstanding of system capabilities (Level 2 â‰  Level 4!)\n",
    " - Over-reliance and complacency\n",
    " - Reduced monitoring over time\n",
    "\n",
    "3. **Design trade-offs:**\n",
    " - Cost: No LiDAR (Tesla's camera-only approach)\n",
    " - User experience: Hands-on-wheel enforcement initially lax\n",
    " - False positive reduction â†’ missed true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of sensor limitations\n",
    "sensor_limitations = pd.DataFrame({\n",
    "    'Scenario': [\n",
    "        'White truck, bright sky',\n",
    "        'Stationary barrier',\n",
    "        'Night, dark clothing',\n",
    "        'Rain, fog',\n",
    "        'Direct sunlight glare'\n",
    "    ],\n",
    "    'Camera_Only': ['âŒ Fails', 'âš ï¸ May miss', 'âŒ Fails', 'âš ï¸ Degraded', 'âŒ Fails'],\n",
    "    'Camera_LiDAR': ['âœ… LiDAR detects', 'âœ… Both detect', 'âœ… LiDAR detects', 'âš ï¸ LiDAR degraded', 'âœ… LiDAR works'],\n",
    "    'Camera_LiDAR_Radar': ['âœ…âœ… Redundant', 'âœ…âœ… Redundant', 'âœ…âœ… Redundant', 'âœ… Radar works', 'âœ…âœ… Redundant']\n",
    "})\n",
    "\n",
    "display(sensor_limitations)\n",
    "\n",
    "print(\"\\nðŸ’¡ Lesson: Sensor redundancy critical for safety!\")\n",
    "print(\"   Camera-only systems have fundamental limitations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study 3: Cruise SF Incident (October 2023)\n",
    "\n",
    "### Incident Overview\n",
    "\n",
    "**Date:** October 2, 2023 \n",
    "**Location:** San Francisco, California \n",
    "**Vehicle:** Cruise robotaxi (Level 4, no driver) \n",
    "**Outcome:** Pedestrian injured and dragged by vehicle\n",
    "\n",
    "### What Happened?\n",
    "\n",
    "1. **Initial impact:** Human-driven vehicle struck pedestrian, throwing them into Cruise vehicle's path\n",
    "2. **Cruise response:** Autonomous vehicle detected impact and **braked**\n",
    "3. **Problem:** Vehicle then attempted to **pull over** (normal protocol)\n",
    "4. **Tragedy:** Pedestrian was trapped under vehicle and **dragged 20 feet**\n",
    "5. **Outcome:** Pedestrian severely injured\n",
    "\n",
    "### Root Causes\n",
    "\n",
    "**1. Decision-making failure:**\n",
    "- âŒ System did not detect pedestrian **under** the vehicle\n",
    "- âŒ \"Pull over after collision\" protocol inappropriate for this scenario\n",
    "- âŒ No sensor coverage for objects under vehicle\n",
    "\n",
    "**2. Communication failure:**\n",
    "- âŒ Cruise initially did not disclose dragging to regulators\n",
    "- âŒ Showed video of initial impact but not subsequent dragging\n",
    "- âŒ Damaged trust with California DMV and public\n",
    "\n",
    "**3. Safety process gaps:**\n",
    "- âŒ Insufficient testing of \"secondary collision\" scenarios\n",
    "- âŒ Edge case not covered in safety validation\n",
    "- âŒ No fail-safe for unknown object under vehicle\n",
    "\n",
    "### Regulatory Consequence\n",
    "\n",
    "- California DMV **suspended** Cruise's robotaxi operations\n",
    "- Cruise **recalled** all vehicles for software update\n",
    "- Industry-wide scrutiny of Level 4 deployment safety\n",
    "\n",
    "### Lessons Learned\n",
    "\n",
    "1. **Expect the unexpected:** Even low-probability scenarios can occur\n",
    "2. **Complete sensor coverage:** Including under-vehicle sensors\n",
    "3. **Context-aware behavior:** \"Pull over\" not always safe action\n",
    "4. **Transparency:** Full disclosure critical for trust and learning\n",
    "5. **Testing scope:** Include multi-stage incidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Failure Taxonomy for AV Perception Systems\n",
    "\n",
    "A systematic classification of how perception systems can fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create failure taxonomy\n",
    "failure_taxonomy = {\n",
    "    'Detection Failures': {\n",
    "        'False Negative (Miss)': 'Object exists but not detected (e.g., Uber pedestrian initially)',\n",
    "        'False Positive (Phantom)': 'Detection of non-existent object (e.g., radar overhead sign)',\n",
    "        'Late Detection': 'Object detected but too late for safe response'\n",
    "    },\n",
    "    'Classification Failures': {\n",
    "        'Misclassification': 'Object detected but wrong class (e.g., bicycle as vehicle)',\n",
    "        'Classification Instability': 'Fluctuating class labels (e.g., Uber unknownâ†’vehicleâ†’bicycle)',\n",
    "        'Unknown Class': 'Novel object not in training data'\n",
    "    },\n",
    "    'Tracking Failures': {\n",
    "        'Lost Track': 'Object disappears from tracking (occlusion, sensor limit)',\n",
    "        'ID Switch': 'Object IDs swapped between similar objects',\n",
    "        'Trajectory Error': 'Incorrect prediction of object motion'\n",
    "    },\n",
    "    'Localization Failures': {\n",
    "        'Position Error': 'Incorrect spatial location of object or vehicle',\n",
    "        'Map Mismatch': 'HD map outdated or incorrect',\n",
    "        'GPS Failure': 'Lost or degraded positioning signal'\n",
    "    },\n",
    "    'Sensor Failures': {\n",
    "        'Hardware Fault': 'Camera, LiDAR, radar malfunction',\n",
    "        'Calibration Drift': 'Sensors misaligned over time',\n",
    "        'Environmental Degradation': 'Rain, fog, sun glare, darkness',\n",
    "        'Occlusion': 'Sensor view blocked (dirt, obstruction)'\n",
    "    },\n",
    "    'Fusion Failures': {\n",
    "        'Conflicting Sensors': 'Camera says \"car\", LiDAR says \"empty\"',\n",
    "        'Sensor Timeout': 'Sensor data arrives late, desynchronized',\n",
    "        'Fusion Logic Error': 'Incorrect weighting or combination'\n",
    "    },\n",
    "    'System-Level Failures': {\n",
    "        'Computational Overload': 'Processing cannot keep up with sensor data rate',\n",
    "        'Software Bug': 'Code error causes incorrect behavior',\n",
    "        'Inadequate ODD': 'Operating outside design domain'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display as structured data\n",
    "print(\"ðŸ“Š AV PERCEPTION FAILURE TAXONOMY\\n\" + \"=\"*60)\n",
    "for category, failures in failure_taxonomy.items():\n",
    "    print(f\"\\n{category.upper()}\")\n",
    "    print(\"-\" * 60)\n",
    "    for failure_type, description in failures.items():\n",
    "        print(f\"  â€¢ {failure_type}: {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize failure taxonomy as tree\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.axis('off')\n",
    "\n",
    "# Root\n",
    "root_box = FancyBboxPatch((3.5, 8.5), 3, 0.8, boxstyle=\"round,pad=0.1\", \n",
    "                          facecolor='#ff6b6b', edgecolor='black', linewidth=2)\n",
    "ax.add_patch(root_box)\n",
    "ax.text(5, 8.9, 'PERCEPTION FAILURES', ha='center', va='center', \n",
    "        fontsize=14, fontweight='bold', color='white')\n",
    "\n",
    "# Categories\n",
    "categories = list(failure_taxonomy.keys())\n",
    "colors = ['#4ecdc4', '#45b7d1', '#96ceb4', '#feca57', '#ff6b6b', '#a29bfe', '#fd79a8']\n",
    "x_positions = [0.5, 2, 3.5, 5, 6.5, 8, 9.5]\n",
    "y_position = 6.5\n",
    "\n",
    "for i, (category, color) in enumerate(zip(categories, colors)):\n",
    "    x = x_positions[i] if i < len(x_positions) else 0.5 + (i % 7) * 1.5\n",
    "    y = y_position if i < 7 else y_position - 2\n",
    "    \n",
    "    # Draw box\n",
    "    box = FancyBboxPatch((x - 0.4, y), 0.8, 0.6, boxstyle=\"round,pad=0.05\",\n",
    "                         facecolor=color, edgecolor='black', linewidth=1.5, alpha=0.7)\n",
    "    ax.add_patch(box)\n",
    "    \n",
    "    # Add text\n",
    "    text = category.replace(' Failures', '').replace(' ', '\\n')\n",
    "    ax.text(x, y + 0.3, text, ha='center', va='center', \n",
    "            fontsize=8, fontweight='bold')\n",
    "    \n",
    "    # Draw connection to root\n",
    "    ax.plot([5, x], [8.5, y + 0.6], 'k-', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Add title\n",
    "ax.text(5, 9.7, 'Failure Taxonomy for AV Perception Systems', \n",
    "        ha='center', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Use this taxonomy to systematically analyze any AV perception failure!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Root Cause Analysis Framework\n",
    "\n",
    "### The \"5 Whys\" Method\n",
    "\n",
    "**Example: Uber Crash**\n",
    "\n",
    "1. **Why did the accident occur?** \n",
    " â†’ Vehicle did not brake for pedestrian\n",
    "\n",
    "2. **Why didn't it brake?** \n",
    " â†’ Perception system didn't reliably classify the pedestrian\n",
    "\n",
    "3. **Why didn't it classify reliably?** \n",
    " â†’ System reset trajectory prediction with each classification change\n",
    "\n",
    "4. **Why did it reset predictions?** \n",
    " â†’ Software design flaw: coupled classification and planning\n",
    "\n",
    "5. **Why was this design flaw present?** \n",
    " â†’ Insufficient testing of edge cases (jaywalking scenarios)\n",
    "\n",
    "**Root cause:** Inadequate testing processes and software architecture\n",
    "\n",
    "### Fishbone (Ishikawa) Diagram\n",
    "\n",
    "Categorize contributing factors:\n",
    "- **People:** Safety driver inattention\n",
    "- **Process:** Insufficient testing, weak safety culture\n",
    "- **Technology:** Classification instability, disabled emergency brake\n",
    "- **Environment:** Night, jaywalking (not at crosswalk)\n",
    "- **Management:** Pressure to reduce interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root cause analysis example for Uber crash\n",
    "root_cause_factors = pd.DataFrame({\n",
    "    'Category': ['Technical', 'Technical', 'Technical', 'Process', 'Process', \n",
    "                 'Human', 'Human', 'Organizational', 'Environmental'],\n",
    "    'Contributing_Factor': [\n",
    "        'Classification instability',\n",
    "        'Emergency braking disabled',\n",
    "        'Path prediction reset on class change',\n",
    "        'Inadequate edge case testing',\n",
    "        'No jaywalking scenarios tested',\n",
    "        'Safety driver distraction (phone)',\n",
    "        'No driver monitoring system',\n",
    "        'Pressure to reduce interventions',\n",
    "        'Night operation, no crosswalk'\n",
    "    ],\n",
    "    'Severity': ['Critical', 'Critical', 'High', 'High', 'High', \n",
    "                 'Critical', 'High', 'Medium', 'Medium'],\n",
    "    'Mitigation': [\n",
    "        'Stable multi-frame classification',\n",
    "        'Never disable safety-critical systems',\n",
    "        'Decouple classification from planning',\n",
    "        'Expand test scenario library',\n",
    "        'Systematic ODD boundary testing',\n",
    "        'Driver monitoring system (DMS)',\n",
    "        'Mandatory DMS with alerts',\n",
    "        'Safety-first culture, independent oversight',\n",
    "        'Improved night perception, assume jaywalking'\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(root_cause_factors)\n",
    "\n",
    "print(\"\\nâœ… Each contributing factor has specific mitigation!\")\n",
    "print(\"   Systematic analysis â†’ Systematic improvements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Patterns Across AV Failures\n",
    "\n",
    "### Technical Patterns\n",
    "\n",
    "1. **Sensor limitations:**\n",
    " - Camera: Lighting (glare, darkness), weather, contrast\n",
    " - LiDAR: Rain, snow, fog (though better than camera)\n",
    " - Radar: Low resolution, ground reflections\n",
    "\n",
    "2. **Perception challenges:**\n",
    " - Stationary objects (trucks, barriers)\n",
    " - Unusual poses or orientations\n",
    " - Occlusions (partial visibility)\n",
    " - Out-of-distribution objects\n",
    "\n",
    "3. **System design issues:**\n",
    " - Insufficient redundancy\n",
    " - Single-point failures\n",
    " - Inadequate ODD definition\n",
    " - Edge case coverage gaps\n",
    "\n",
    "### Human Factors\n",
    "\n",
    "1. **Over-reliance:**\n",
    " - Misunderstanding system capabilities\n",
    " - Complacency over time\n",
    " - Attention degradation\n",
    "\n",
    "2. **Mode confusion:**\n",
    " - Not knowing which mode is active\n",
    " - Level 2 treated as Level 4\n",
    " - Unclear handover protocols\n",
    "\n",
    "### Organizational Issues\n",
    "\n",
    "1. **Development pressure:**\n",
    " - Speed over safety trade-offs\n",
    " - Inadequate testing\n",
    " - Premature deployment\n",
    "\n",
    "2. **Safety culture:**\n",
    " - Insufficient oversight\n",
    " - Lack of transparency\n",
    " - No systematic learning from near-misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of failure types across incidents\n",
    "failure_frequency = pd.DataFrame({\n",
    "    'Failure_Type': [\n",
    "        'Camera perception failure',\n",
    "        'Driver/operator inattention',\n",
    "        'Stationary object not detected',\n",
    "        'Weather/lighting degradation',\n",
    "        'Classification error',\n",
    "        'System design flaw',\n",
    "        'Inadequate testing',\n",
    "        'Single sensor type (camera only)'\n",
    "    ],\n",
    "    'Frequency': [6, 5, 4, 3, 3, 4, 5, 4],\n",
    "    'Severity': ['Critical', 'Critical', 'Critical', 'High', 'High', 'Critical', 'High', 'High']\n",
    "})\n",
    "\n",
    "# Sort by frequency\n",
    "failure_frequency = failure_frequency.sort_values('Frequency', ascending=True)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors = ['darkred' if s == 'Critical' else 'orange' for s in failure_frequency['Severity']]\n",
    "ax.barh(failure_frequency['Failure_Type'], failure_frequency['Frequency'], color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Frequency in Major Incidents', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Common Failure Types Across AV Incidents', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='darkred', alpha=0.7, label='Critical Severity'),\n",
    "    Patch(facecolor='orange', alpha=0.7, label='High Severity')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Top failure patterns:\")\n",
    "print(\"   1. Camera perception limitations\")\n",
    "print(\"   2. Human factor (operator inattention)\")\n",
    "print(\"   3. Inadequate testing and validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise: Failure Analysis\n",
    "\n",
    "**Scenario:** An autonomous shuttle operating on a university campus (Level 4, 25 km/h max) has an incident:\n",
    "\n",
    "- **Conditions:** Early morning, light fog, wet road\n",
    "- **Event:** Student on electric scooter crosses in front of shuttle at intersection\n",
    "- **Result:** Shuttle does not brake, student swerves to avoid collision\n",
    "- **System logs:** Object detected 2.5 seconds before, classified as \"bicycle\" with 45% confidence\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "1. **Classify the failure** using the taxonomy above\n",
    "2. **Apply \"5 Whys\"** to find root cause\n",
    "3. **Identify contributing factors** (technical, process, environmental)\n",
    "4. **Propose mitigations** for each factor\n",
    "5. **Lessons learned** for system design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete your analysis\n",
    "\n",
    "your_analysis = {\n",
    "    'failure_classification': '',  # e.g., \"Detection Failure: Late Detection\"\n",
    "    'five_whys': [\n",
    "        # Add your 5 why questions and answers\n",
    "    ],\n",
    "    'contributing_factors': {\n",
    "        'technical': [],\n",
    "        'process': [],\n",
    "        'environmental': []\n",
    "    },\n",
    "    'mitigations': [\n",
    "        # Your proposed mitigations\n",
    "    ],\n",
    "    'lessons_learned': [\n",
    "        # Key takeaways for design\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Print your analysis\n",
    "print(\"Your Failure Analysis:\")\n",
    "print(f\"\\nClassification: {your_analysis['failure_classification']}\")\n",
    "print(\"\\n5 Whys:\")\n",
    "for i, why in enumerate(your_analysis['five_whys'], 1):\n",
    "    print(f\"  {i}. {why}\")\n",
    "\n",
    "print(\"\\nðŸ¤” Reflection:\")\n",
    "print(\"   - Could this incident have been prevented?\")\n",
    "print(\"   - What would you change in the system design?\")\n",
    "print(\"   - How does this relate to ISO 21448 SOTIF?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### Real-World Failures Teach Us\n",
    "- **Uber ATG (2018):** Classification instability + disabled safety systems + human factors\n",
    "- **Tesla Autopilot:** Camera limitations + driver over-reliance + edge cases\n",
    "- **Cruise SF (2023):** Decision-making failure + inadequate sensor coverage\n",
    "\n",
    "### Failure Taxonomy\n",
    "- **Seven categories:** Detection, Classification, Tracking, Localization, Sensor, Fusion, System-level\n",
    "- **Use for systematic analysis** of any perception failure\n",
    "\n",
    "### Common Patterns\n",
    "- **Technical:** Camera limitations, stationary objects, lighting/weather\n",
    "- **Human:** Over-reliance, mode confusion, inattention\n",
    "- **Organizational:** Speed over safety, inadequate testing\n",
    "\n",
    "### Root Cause Analysis\n",
    "- **5 Whys method:** Dig deeper than surface symptoms\n",
    "- **Fishbone diagram:** Categorize contributing factors\n",
    "- **Systematic mitigations:** Address each factor\n",
    "\n",
    "### Design Principles from Failures\n",
    "1. âœ… **Never disable safety systems**\n",
    "2. âœ… **Multi-modal sensing** (camera + LiDAR + radar)\n",
    "3. âœ… **Fail safely** when uncertain\n",
    "4. âœ… **Comprehensive testing** including edge cases\n",
    "5. âœ… **Safety culture** over development speed\n",
    "6. âœ… **Transparent reporting** and learning\n",
    "\n",
    "---\n",
    "\n",
    "## Next: Out-of-Distribution Detection\n",
    "\n",
    "Now that we understand **what** can go wrong, let's learn **how to detect** when the system encounters unknown situations!\n",
    "\n",
    "**Ready?** Open `08_OOD_Detection.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook created by Milin Patel | Hochschule Kempten* \n",
    "*Last updated: 2025-01-18*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}