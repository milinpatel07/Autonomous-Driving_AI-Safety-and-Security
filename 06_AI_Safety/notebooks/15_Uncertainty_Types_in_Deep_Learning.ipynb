{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "Copyright (c) 2025 Milin Patel\n",
    "Hochschule Kempten - University of Applied Sciences\n",
    "\n",
    "Autonomous Driving: AI Safety and Security Workshop\n",
    "This project is licensed under the MIT License.\n",
    "See LICENSE file in the root directory for full license text.\n",
    "-->\n",
    "\n",
    "*Copyright ¬© 2025 Milin Patel. All Rights Reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 15: Uncertainty Types in Deep Learning\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/milinpatel07/Autonomous-Driving_AI-Safety-and-Security/blob/main/AV_Perception_Safety_Workshop/Session_4_Uncertainty_Estimation_and_Validation/notebooks/15_Uncertainty_Types_in_Deep_Learning.ipynb)\n",
    "\n",
    "**Session 4: Uncertainty Estimation and Validation**  \n",
    "\n",
    "## Learning Objectives\n",
    "- Understand aleatoric vs epistemic uncertainty\n",
    "- Identify sources of uncertainty in AV perception\n",
    "- Recognize why uncertainty quantification is critical for safety\n",
    "- Connect uncertainty to ISO 26262 and ISO 21448 (SOTIF)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Why Uncertainty Matters for Autonomous Vehicles:**\n",
    "\n",
    "Imagine an AV perception system detecting a pedestrian with 95% confidence. Should the vehicle brake?\n",
    "- If the model is well-calibrated: Yes, high confidence means high probability.\n",
    "- If the model is overconfident: Maybe not - the 95% could be meaningless.\n",
    "- If we know the model is uncertain (epistemic uncertainty is high): We should be cautious.\n",
    "\n",
    "**Safety standards require uncertainty awareness:**\n",
    "- **ISO 26262** (functional safety): Requires validation that the system handles uncertainty\n",
    "- **ISO 21448** (SOTIF): Directly addresses performance limitations and unknown unsafe scenarios\n",
    "\n",
    "Uncertainty quantification helps us:\n",
    "1. Detect out-of-distribution scenarios\n",
    "2. Trigger fallback behaviors\n",
    "3. Understand model limitations\n",
    "4. Provide safety evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip install -q torch torchvision matplotlib seaborn numpy scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Types of Uncertainty\n",
    "\n",
    "### 1.1 Aleatoric Uncertainty (Data Uncertainty)\n",
    "\n",
    "**Definition:** Irreducible uncertainty inherent in the data itself.\n",
    "\n",
    "**Characteristics:**\n",
    "- Cannot be reduced by collecting more data\n",
    "- Due to noise in observations\n",
    "- Also called \"statistical uncertainty\" or \"data uncertainty\"\n",
    "\n",
    "**Sources in AV Perception:**\n",
    "- **Sensor noise:** Camera noise, LiDAR measurement errors\n",
    "- **Environmental conditions:** Rain drops on camera, fog, glare\n",
    "- **Motion blur:** Fast-moving objects\n",
    "- **Occlusions:** Partially visible pedestrians\n",
    "- **Label noise:** Inconsistent human annotations\n",
    "\n",
    "**Two types:**\n",
    "- **Homoscedastic:** Constant across all inputs (e.g., camera sensor noise)\n",
    "- **Heteroscedastic:** Varies with input (e.g., more uncertainty for distant objects)\n",
    "\n",
    "### 1.2 Epistemic Uncertainty (Model Uncertainty)\n",
    "\n",
    "**Definition:** Reducible uncertainty due to lack of knowledge.\n",
    "\n",
    "**Characteristics:**\n",
    "- Can be reduced with more training data\n",
    "- Due to limited training data or model capacity\n",
    "- Also called \"model uncertainty\" or \"knowledge uncertainty\"\n",
    "\n",
    "**Sources in AV Perception:**\n",
    "- **Insufficient training data:** Rare scenarios not well-represented\n",
    "- **Out-of-distribution inputs:** Novel objects or conditions\n",
    "- **Model capacity:** Limited representational power\n",
    "- **Domain shift:** Training in sunny weather, testing in snow\n",
    "\n",
    "**Key insight for safety:** High epistemic uncertainty signals \"I haven't seen this before\" ‚Üí safety-critical for AVs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing Uncertainty Types\n",
    "\n",
    "Let's create a simple toy problem to visualize both types of uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with gap (high epistemic uncertainty region)\n",
    "def create_dataset_with_gap():\n",
    "    \"\"\"Create 1D regression dataset with a gap to simulate OOD region.\"\"\"\n",
    "    # Training data: two separate regions with gap\n",
    "    x_train_1 = np.linspace(-4, -1, 30)\n",
    "    x_train_2 = np.linspace(1, 4, 30)\n",
    "    x_train = np.concatenate([x_train_1, x_train_2])\n",
    "    \n",
    "    # True function\n",
    "    y_true = np.sin(x_train * 2)\n",
    "    \n",
    "    # Add aleatoric noise (heteroscedastic - more noise for larger |x|)\n",
    "    noise_std = 0.1 + 0.05 * np.abs(x_train)\n",
    "    y_train = y_true + np.random.randn(len(x_train)) * noise_std\n",
    "    \n",
    "    # Test data: includes the gap region\n",
    "    x_test = np.linspace(-5, 5, 200)\n",
    "    \n",
    "    return x_train, y_train, x_test, noise_std\n",
    "\n",
    "x_train, y_train, x_test, noise_std = create_dataset_with_gap()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x_train, y_train, alpha=0.6, s=50, label='Training data')\n",
    "plt.axvspan(-1, 1, alpha=0.2, color='red', label='Gap (high epistemic uncertainty)')\n",
    "plt.xlabel('Input x')\n",
    "plt.ylabel('Output y')\n",
    "plt.title('Dataset with Gap (OOD Region)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Show heteroscedastic aleatoric uncertainty\n",
    "for i in range(0, len(x_train), 5):\n",
    "    plt.errorbar(x_train[i], y_train[i], yerr=noise_std[i]*2, \n",
    "                 fmt='o', alpha=0.5, capsize=3)\n",
    "plt.xlabel('Input x')\n",
    "plt.ylabel('Output y')\n",
    "plt.title('Aleatoric Uncertainty (Heteroscedastic)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Dataset characteristics:\")\n",
    "print(f\"- Training samples: {len(x_train)}\")\n",
    "print(f\"- Gap region: [-1, 1] (no training data)\")\n",
    "print(f\"- Aleatoric noise: heteroscedastic (varies with |x|)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple neural network for regression\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, hidden_size=50):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(1, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Train the model\n",
    "model = SimpleNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.FloatTensor(x_train.reshape(-1, 1))\n",
    "y_train_tensor = torch.FloatTensor(y_train.reshape(-1, 1))\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "losses = []\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_train_tensor)\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/1000, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions (single model - no uncertainty yet)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.FloatTensor(x_test.reshape(-1, 1))\n",
    "    y_pred = model(X_test_tensor).numpy().flatten()\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(x_train, y_train, alpha=0.6, s=50, label='Training data', c='blue')\n",
    "plt.plot(x_test, y_pred, 'r-', linewidth=2, label='Model prediction')\n",
    "plt.axvspan(-1, 1, alpha=0.2, color='red', label='Gap (OOD region)')\n",
    "plt.xlabel('Input x')\n",
    "plt.ylabel('Output y')\n",
    "plt.title('Single Model Prediction (No Uncertainty Information!)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚ö†Ô∏è Problem: The model makes confident predictions in the gap region!\")\n",
    "print(\"Without uncertainty estimation, we don't know the model is unreliable there.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sources of Uncertainty in AV Perception\n",
    "\n",
    "### 3.1 Sensor-Level Uncertainty (Aleatoric)\n",
    "\n",
    "**Camera:**\n",
    "- Photon noise (especially in low light)\n",
    "- Motion blur from fast movement\n",
    "- Lens distortion at edges\n",
    "- Rain drops, dirt, glare\n",
    "\n",
    "**LiDAR:**\n",
    "- Range measurement noise (~2-3 cm for modern LiDAR)\n",
    "- Reduced returns on dark/wet surfaces\n",
    "- Interference from other LiDAR\n",
    "- Sparse point clouds for distant objects\n",
    "\n",
    "**Radar:**\n",
    "- Angular resolution limitations\n",
    "- Multipath reflections\n",
    "- Ghost targets\n",
    "\n",
    "### 3.2 Perception-Level Uncertainty (Both Types)\n",
    "\n",
    "**Aleatoric:**\n",
    "- Occlusions (pedestrian behind car)\n",
    "- Truncated objects (only part visible)\n",
    "- Ambiguous situations (is it a bag or animal?)\n",
    "\n",
    "**Epistemic:**\n",
    "- Novel objects not in training data\n",
    "- Rare scenarios (e.g., overturned truck)\n",
    "- Domain shift (new city, new weather)\n",
    "- Corner cases\n",
    "\n",
    "### 3.3 Simulation of AV Perception Uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate different uncertainty sources\n",
    "def simulate_perception_uncertainty():\n",
    "    \"\"\"Simulate various uncertainty sources in AV perception.\"\"\"\n",
    "    \n",
    "    scenarios = [\n",
    "        {\n",
    "            'name': 'Clear Weather, Well-Lit',\n",
    "            'aleatoric': 0.02,  # Low sensor noise\n",
    "            'epistemic': 0.01,  # Well-trained scenario\n",
    "            'color': 'green'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Rain, Nighttime',\n",
    "            'aleatoric': 0.15,  # High sensor noise\n",
    "            'epistemic': 0.05,  # Still trained scenario\n",
    "            'color': 'yellow'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Novel Object (Construction)',\n",
    "            'aleatoric': 0.03,  # Normal sensor noise\n",
    "            'epistemic': 0.25,  # Not in training data!\n",
    "            'color': 'orange'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Severe Occlusion',\n",
    "            'aleatoric': 0.20,  # Missing information\n",
    "            'epistemic': 0.08,  # Trained but challenging\n",
    "            'color': 'orange'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Unknown Scenario (Snow)',\n",
    "            'aleatoric': 0.12,  # Moderate sensor issues\n",
    "            'epistemic': 0.35,  # Never seen snow!\n",
    "            'color': 'red'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Visualize\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Bar chart\n",
    "    names = [s['name'] for s in scenarios]\n",
    "    aleatoric = [s['aleatoric'] for s in scenarios]\n",
    "    epistemic = [s['epistemic'] for s in scenarios]\n",
    "    colors = [s['color'] for s in scenarios]\n",
    "    \n",
    "    x = np.arange(len(names))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1.bar(x - width/2, aleatoric, width, label='Aleatoric (Data)', alpha=0.8)\n",
    "    ax1.bar(x + width/2, epistemic, width, label='Epistemic (Model)', alpha=0.8)\n",
    "    ax1.set_ylabel('Uncertainty Level')\n",
    "    ax1.set_title('Uncertainty Sources in Different AV Scenarios')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(names, rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Scatter plot: total uncertainty\n",
    "    total_uncertainty = [a + e for a, e in zip(aleatoric, epistemic)]\n",
    "    for i, (a, e, name, color) in enumerate(zip(aleatoric, epistemic, names, colors)):\n",
    "        ax2.scatter(a, e, s=500, c=color, alpha=0.6, edgecolors='black', linewidth=2)\n",
    "        ax2.annotate(str(i+1), (a, e), ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    ax2.set_xlabel('Aleatoric Uncertainty (Irreducible)')\n",
    "    ax2.set_ylabel('Epistemic Uncertainty (Reducible)')\n",
    "    ax2.set_title('Uncertainty Space Map')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add diagonal lines for total uncertainty\n",
    "    for total in [0.1, 0.2, 0.3, 0.4]:\n",
    "        x_line = np.linspace(0, total, 100)\n",
    "        y_line = total - x_line\n",
    "        ax2.plot(x_line, y_line, 'k--', alpha=0.2)\n",
    "        ax2.text(total/2, total/2, f'Total={total:.1f}', \n",
    "                rotation=-45, alpha=0.5, fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print insights\n",
    "    print(\"\\nüéØ Key Insights:\")\n",
    "    print(\"\\n1. GREEN scenarios: Low total uncertainty ‚Üí Safe to operate\")\n",
    "    print(\"2. YELLOW scenarios: Moderate uncertainty ‚Üí Operate with caution\")\n",
    "    print(\"3. ORANGE scenarios: High uncertainty ‚Üí Consider fallback\")\n",
    "    print(\"4. RED scenarios: Very high epistemic uncertainty ‚Üí STOP or minimal risk condition!\")\n",
    "    print(\"\\n5. High EPISTEMIC uncertainty = 'Never seen this before' ‚Üí Most dangerous!\")\n",
    "    print(\"6. High ALEATORIC uncertainty = 'Noisy data' ‚Üí Can handle with robust design\")\n",
    "    \n",
    "    return scenarios\n",
    "\n",
    "scenarios = simulate_perception_uncertainty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example: Pedestrian Detection with Uncertainty\n",
    "\n",
    "Let's simulate a pedestrian detection scenario with both uncertainty types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pedestrian_detection_uncertainty_example():\n",
    "    \"\"\"\n",
    "    Simulate pedestrian detection with different uncertainty conditions.\n",
    "    \"\"\"\n",
    "    \n",
    "    cases = [\n",
    "        {\n",
    "            'scenario': 'Clear view, daytime',\n",
    "            'confidence': 0.95,\n",
    "            'aleatoric_std': 0.02,\n",
    "            'epistemic_std': 0.01,\n",
    "            'decision': 'High confidence - Normal operation',\n",
    "            'safety_level': 'Safe'\n",
    "        },\n",
    "        {\n",
    "            'scenario': 'Partial occlusion',\n",
    "            'confidence': 0.78,\n",
    "            'aleatoric_std': 0.15,\n",
    "            'epistemic_std': 0.05,\n",
    "            'decision': 'Moderate confidence - Monitor closely',\n",
    "            'safety_level': 'Caution'\n",
    "        },\n",
    "        {\n",
    "            'scenario': 'Person in unusual pose',\n",
    "            'confidence': 0.72,\n",
    "            'aleatoric_std': 0.05,\n",
    "            'epistemic_std': 0.20,\n",
    "            'decision': 'High epistemic uncertainty - Slow down',\n",
    "            'safety_level': 'Warning'\n",
    "        },\n",
    "        {\n",
    "            'scenario': 'Person-like object (statue)',\n",
    "            'confidence': 0.65,\n",
    "            'aleatoric_std': 0.08,\n",
    "            'epistemic_std': 0.25,\n",
    "            'decision': 'Very uncertain - Conservative action',\n",
    "            'safety_level': 'Alert'\n",
    "        },\n",
    "        {\n",
    "            'scenario': 'Night + rain + occlusion',\n",
    "            'confidence': 0.55,\n",
    "            'aleatoric_std': 0.25,\n",
    "            'epistemic_std': 0.15,\n",
    "            'decision': 'High total uncertainty - Reduce speed significantly',\n",
    "            'safety_level': 'Danger'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, case in enumerate(cases):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Simulate detection distribution\n",
    "        confidence = case['confidence']\n",
    "        total_std = np.sqrt(case['aleatoric_std']**2 + case['epistemic_std']**2)\n",
    "        \n",
    "        # Create confidence distribution\n",
    "        x = np.linspace(0, 1, 200)\n",
    "        \n",
    "        # Aleatoric component (narrow, fixed)\n",
    "        aleatoric_dist = np.exp(-0.5 * ((x - confidence) / case['aleatoric_std'])**2)\n",
    "        aleatoric_dist /= (case['aleatoric_std'] * np.sqrt(2 * np.pi))\n",
    "        \n",
    "        # Total uncertainty (wider)\n",
    "        total_dist = np.exp(-0.5 * ((x - confidence) / total_std)**2)\n",
    "        total_dist /= (total_std * np.sqrt(2 * np.pi))\n",
    "        \n",
    "        # Plot\n",
    "        ax.fill_between(x, 0, total_dist, alpha=0.3, color='red', \n",
    "                        label=f'Total Unc. (œÉ={total_std:.3f})')\n",
    "        ax.fill_between(x, 0, aleatoric_dist, alpha=0.5, color='blue',\n",
    "                       label=f'Aleatoric (œÉ={case[\"aleatoric_std\"]:.3f})')\n",
    "        ax.axvline(confidence, color='black', linestyle='--', linewidth=2, \n",
    "                  label=f'Conf={confidence:.2f}')\n",
    "        \n",
    "        # Decision threshold\n",
    "        ax.axvline(0.8, color='green', linestyle=':', linewidth=1, alpha=0.5)\n",
    "        ax.text(0.8, ax.get_ylim()[1]*0.9, 'Decision\\nThreshold', \n",
    "               ha='center', fontsize=8, color='green')\n",
    "        \n",
    "        # Safety color coding\n",
    "        color_map = {\n",
    "            'Safe': 'lightgreen',\n",
    "            'Caution': 'yellow',\n",
    "            'Warning': 'orange',\n",
    "            'Alert': 'orangered',\n",
    "            'Danger': 'red'\n",
    "        }\n",
    "        ax.set_facecolor(color_map[case['safety_level']])\n",
    "        ax.set_alpha(0.1)\n",
    "        \n",
    "        ax.set_xlabel('Confidence')\n",
    "        ax.set_ylabel('Probability Density')\n",
    "        ax.set_title(f\"{case['scenario']}\\n{case['safety_level']}\", fontsize=10, fontweight='bold')\n",
    "        ax.legend(fontsize=8, loc='upper left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xlim([0, 1])\n",
    "    \n",
    "    # Remove extra subplot\n",
    "    axes[-1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print decision table\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PEDESTRIAN DETECTION UNCERTAINTY ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\n{'Scenario':<30} {'Conf':<6} {'Aleat':<6} {'Epist':<6} {'Total':<6} {'Decision':<40}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for case in cases:\n",
    "        total = np.sqrt(case['aleatoric_std']**2 + case['epistemic_std']**2)\n",
    "        print(f\"{case['scenario']:<30} {case['confidence']:<6.2f} \"\n",
    "              f\"{case['aleatoric_std']:<6.3f} {case['epistemic_std']:<6.3f} \"\n",
    "              f\"{total:<6.3f} {case['decision']:<40}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"\\nüîë Decision Logic:\")\n",
    "    print(\"1. High confidence + Low epistemic uncertainty ‚Üí Normal operation\")\n",
    "    print(\"2. Moderate confidence OR Moderate epistemic ‚Üí Caution, monitor\")\n",
    "    print(\"3. Low confidence OR High epistemic ‚Üí Slow down, conservative\")\n",
    "    print(\"4. Very high total uncertainty ‚Üí Significant speed reduction or stop\")\n",
    "    print(\"\\n‚ö†Ô∏è  Epistemic uncertainty is MORE critical than aleatoric for safety decisions!\")\n",
    "\n",
    "pedestrian_detection_uncertainty_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Why Uncertainty Matters for Safety Standards\n",
    "\n",
    "### 5.1 ISO 26262 (Functional Safety)\n",
    "\n",
    "**Relevant sections:**\n",
    "- **Part 6:** Product development at the software level\n",
    "- **Part 8:** Supporting processes (validation)\n",
    "\n",
    "**Requirements:**\n",
    "- System must handle internal failures and random hardware failures\n",
    "- Software must be validated for specified operating conditions\n",
    "- **Uncertainty quantification helps:**\n",
    "  - Detect when system is operating outside validated conditions\n",
    "  - Trigger fail-safe mechanisms\n",
    "  - Provide diagnostic coverage\n",
    "\n",
    "### 5.2 ISO 21448 (SOTIF - Safety of the Intended Functionality)\n",
    "\n",
    "**Focus:** Performance limitations and unknown unsafe scenarios\n",
    "\n",
    "**Key concepts:**\n",
    "1. **Known safe scenarios:** Where system performs correctly\n",
    "2. **Known unsafe scenarios:** Where system has known limitations\n",
    "3. **Unknown unsafe scenarios:** Not yet discovered (biggest risk!)\n",
    "4. **Unknown safe scenarios:** System works but not validated\n",
    "\n",
    "**How uncertainty helps:**\n",
    "- **High epistemic uncertainty ‚Üí Likely unknown scenario!**\n",
    "- Can detect transition from known to unknown scenarios\n",
    "- Enables runtime monitoring\n",
    "- Helps define Operational Design Domain (ODD)\n",
    "\n",
    "### 5.3 Uncertainty-Aware Decision Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_aware_decision_logic():\n",
    "    \"\"\"\n",
    "    Demonstrate uncertainty-aware decision logic for AVs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define decision zones\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Create grid\n",
    "    aleatoric_range = np.linspace(0, 0.3, 100)\n",
    "    epistemic_range = np.linspace(0, 0.4, 100)\n",
    "    A, E = np.meshgrid(aleatoric_range, epistemic_range)\n",
    "    \n",
    "    # Decision zones based on total uncertainty and epistemic weight\n",
    "    total_uncertainty = np.sqrt(A**2 + E**2)\n",
    "    epistemic_weight = E / (total_uncertainty + 1e-6)\n",
    "    \n",
    "    # Zone 1: Normal operation (green)\n",
    "    # Zone 2: Caution (yellow)\n",
    "    # Zone 3: Fallback (orange)\n",
    "    # Zone 4: Minimal risk condition (red)\n",
    "    \n",
    "    zones = np.zeros_like(total_uncertainty)\n",
    "    zones[(total_uncertainty < 0.05)] = 1  # Normal\n",
    "    zones[(total_uncertainty >= 0.05) & (total_uncertainty < 0.15) & (E < 0.1)] = 2  # Caution\n",
    "    zones[(total_uncertainty >= 0.05) & (total_uncertainty < 0.15) & (E >= 0.1)] = 3  # Fallback\n",
    "    zones[(total_uncertainty >= 0.15) & (E < 0.15)] = 3  # Fallback\n",
    "    zones[(total_uncertainty >= 0.15) & (E >= 0.15)] = 4  # Minimal risk\n",
    "    zones[(E >= 0.25)] = 4  # High epistemic always triggers minimal risk\n",
    "    \n",
    "    # Plot zones\n",
    "    colors = ['white', 'lightgreen', 'yellow', 'orange', 'red']\n",
    "    labels = ['', 'Normal Operation', 'Caution Mode', 'Fallback', 'Minimal Risk Condition']\n",
    "    \n",
    "    contour = ax.contourf(A, E, zones, levels=[0, 1, 2, 3, 4, 5], \n",
    "                          colors=colors[1:], alpha=0.6)\n",
    "    \n",
    "    # Add contour lines\n",
    "    contour_lines = ax.contour(A, E, zones, levels=[1, 2, 3, 4], \n",
    "                               colors='black', linewidths=2)\n",
    "    \n",
    "    # Plot example scenarios\n",
    "    example_points = [\n",
    "        (0.02, 0.01, 'Clear day', 'o', 'blue'),\n",
    "        (0.15, 0.05, 'Rain', 's', 'cyan'),\n",
    "        (0.05, 0.20, 'Novel object', '^', 'purple'),\n",
    "        (0.20, 0.15, 'Heavy occlusion', 'D', 'brown'),\n",
    "        (0.12, 0.30, 'Unknown scenario', 'X', 'black')\n",
    "    ]\n",
    "    \n",
    "    for aleat, epist, label, marker, color in example_points:\n",
    "        ax.scatter(aleat, epist, s=200, marker=marker, c=color, \n",
    "                  edgecolors='black', linewidth=2, label=label, zorder=5)\n",
    "    \n",
    "    # Add epistemic threshold line\n",
    "    ax.axhline(y=0.25, color='darkred', linestyle='--', linewidth=2, \n",
    "              label='Epistemic threshold')\n",
    "    \n",
    "    ax.set_xlabel('Aleatoric Uncertainty (Irreducible)', fontsize=12)\n",
    "    ax.set_ylabel('Epistemic Uncertainty (Reducible)', fontsize=12)\n",
    "    ax.set_title('Uncertainty-Aware Decision Zones for AV Control\\n(ISO 21448 SOTIF Compliant)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper left', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add zone labels\n",
    "    ax.text(0.02, 0.02, 'NORMAL\\nOPERATION', fontsize=10, fontweight='bold', \n",
    "           ha='center', va='center', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    ax.text(0.20, 0.03, 'CAUTION', fontsize=10, fontweight='bold',\n",
    "           ha='center', va='center', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    ax.text(0.10, 0.12, 'FALLBACK', fontsize=10, fontweight='bold',\n",
    "           ha='center', va='center', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    ax.text(0.20, 0.30, 'MINIMAL RISK\\nCONDITION', fontsize=10, fontweight='bold',\n",
    "           ha='center', va='center', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüöó Uncertainty-Aware AV Decision Logic:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nZone 1 - NORMAL OPERATION:\")\n",
    "    print(\"  ‚Ä¢ Low total uncertainty (<0.05)\")\n",
    "    print(\"  ‚Ä¢ Low epistemic uncertainty\")\n",
    "    print(\"  ‚Üí Action: Normal driving, full functionality\")\n",
    "    print(\"\\nZone 2 - CAUTION MODE:\")\n",
    "    print(\"  ‚Ä¢ Moderate aleatoric uncertainty\")\n",
    "    print(\"  ‚Ä¢ Still low epistemic uncertainty\")\n",
    "    print(\"  ‚Üí Action: Reduce speed slightly, increase safety margins\")\n",
    "    print(\"\\nZone 3 - FALLBACK:\")\n",
    "    print(\"  ‚Ä¢ Moderate epistemic uncertainty OR high total uncertainty\")\n",
    "    print(\"  ‚Ä¢ System entering unfamiliar territory\")\n",
    "    print(\"  ‚Üí Action: Activate fallback system, request human takeover\")\n",
    "    print(\"\\nZone 4 - MINIMAL RISK CONDITION:\")\n",
    "    print(\"  ‚Ä¢ High epistemic uncertainty (>0.25)\")\n",
    "    print(\"  ‚Ä¢ System in unknown scenario (SOTIF critical!)\")\n",
    "    print(\"  ‚Üí Action: Safe stop, minimal risk maneuver, do NOT continue\")\n",
    "    print(\"\\n‚ö†Ô∏è  Key principle: Epistemic uncertainty is weighted MORE heavily!\")\n",
    "    print(\"   'Unknown unknowns' are more dangerous than 'known noise'\")\n",
    "\n",
    "uncertainty_aware_decision_logic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Uncertainty Quantification Methods Overview\n",
    "\n",
    "We'll explore these in detail in the next notebooks:\n",
    "\n",
    "### 6.1 Bayesian Methods\n",
    "- **Bayesian Neural Networks (BNNs):** Full posterior over weights\n",
    "- **Monte Carlo Dropout:** Approximate Bayesian inference\n",
    "- **Variational Inference:** Approximate posterior\n",
    "\n",
    "**Captures:** Primarily epistemic uncertainty\n",
    "\n",
    "### 6.2 Ensemble Methods\n",
    "- **Deep Ensembles:** Multiple independent models\n",
    "- **Snapshot Ensembles:** Single training trajectory\n",
    "- **Batch Ensembles:** Parameter-efficient ensembles\n",
    "\n",
    "**Captures:** Both aleatoric and epistemic uncertainty\n",
    "\n",
    "### 6.3 Single-Model Methods\n",
    "- **Evidential Deep Learning:** Direct uncertainty prediction\n",
    "- **Heteroscedastic Networks:** Learn aleatoric uncertainty\n",
    "- **Deterministic Uncertainty Quantification (DUQ)**\n",
    "\n",
    "**Captures:** Can separate both types\n",
    "\n",
    "### 6.4 Post-hoc Methods\n",
    "- **Temperature Scaling:** Calibrate confidences\n",
    "- **Platt Scaling**\n",
    "- **Isotonic Regression**\n",
    "\n",
    "**Purpose:** Improve calibration of existing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Two Types of Uncertainty:**\n",
    "   - **Aleatoric:** Irreducible noise in data (sensor noise, occlusions)\n",
    "   - **Epistemic:** Reducible model uncertainty (lack of training data, OOD)\n",
    "\n",
    "2. **Sources in AV Perception:**\n",
    "   - Sensor-level: Camera noise, LiDAR errors, weather effects\n",
    "   - Perception-level: Occlusions, novel objects, domain shift\n",
    "\n",
    "3. **Safety Implications:**\n",
    "   - **ISO 26262:** Uncertainty helps detect operating outside validated conditions\n",
    "   - **ISO 21448 (SOTIF):** High epistemic uncertainty signals unknown scenarios\n",
    "\n",
    "4. **Decision Making:**\n",
    "   - Epistemic uncertainty should be weighted MORE heavily\n",
    "   - Unknown scenarios are more dangerous than noisy data\n",
    "   - Enables runtime monitoring and fallback triggers\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the following notebooks, we'll learn:\n",
    "- **Notebook 16:** How to implement MC Dropout and Ensembles\n",
    "- **Notebook 17:** How to calibrate model confidence\n",
    "- **Notebook 18:** How to validate safety of ML-based systems\n",
    "\n",
    "---\n",
    "\n",
    "## Interactive Exercise\n",
    "\n",
    "**Try this:**\n",
    "1. Modify the pedestrian detection scenarios - add your own cases\n",
    "2. Adjust the decision zone thresholds - make them more/less conservative\n",
    "3. Think about: What uncertainty threshold would YOU use for your AV?\n",
    "\n",
    "**Discussion question:**\n",
    "- An AV detects a pedestrian with 90% confidence but high epistemic uncertainty.\n",
    "- Should it brake? Why or why not?\n",
    "- How does this relate to SOTIF?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}