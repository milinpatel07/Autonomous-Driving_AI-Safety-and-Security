{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification and Validation for Functional Safety\n",
    "\n",
    "**ISO 26262 Part 6 (Software) and Part 4 (System) Compliance**\n",
    "\n",
    "Author: Milin Patel  \n",
    "Institution: Hochschule Kempten - University of Applied Sciences\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand the V-Model development lifecycle\n",
    "2. Apply verification methods per ASIL level\n",
    "3. Design validation test cases for safety requirements\n",
    "4. Implement test coverage metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. V-Model Overview\n",
    "\n",
    "### ISO 26262 Development Phases\n",
    "\n",
    "```\n",
    "                    System Design\n",
    "                   /             \\\n",
    "        SW Architecture         System Integration Test\n",
    "             /                           \\\n",
    "    SW Unit Design                 SW Integration Test\n",
    "         /                                   \\\n",
    "   Implementation  ──────────────────>  Unit Test\n",
    "```\n",
    "\n",
    "### Verification vs Validation\n",
    "\n",
    "| Aspect | Verification | Validation |\n",
    "|--------|--------------|------------|\n",
    "| Question | Are we building it right? | Are we building the right thing? |\n",
    "| Focus | Process compliance | Product fitness |\n",
    "| Methods | Reviews, analysis, testing | System testing, field trials |\n",
    "| Reference | Design specifications | User/safety requirements |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Set\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "print(\"V&V Tools Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verification Methods per ASIL\n",
    "\n",
    "ISO 26262-6 Table 9 specifies methods based on ASIL level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASIL(Enum):\n",
    "    QM = 0\n",
    "    A = 1\n",
    "    B = 2\n",
    "    C = 3\n",
    "    D = 4\n",
    "\n",
    "class MethodRecommendation(Enum):\n",
    "    NOT_RECOMMENDED = \"--\"\n",
    "    RECOMMENDED = \"o\"\n",
    "    HIGHLY_RECOMMENDED = \"+\"\n",
    "    STRONGLY_RECOMMENDED = \"++\"\n",
    "\n",
    "# ISO 26262-6 Table 9 - Verification methods for software unit testing\n",
    "VERIFICATION_METHODS = {\n",
    "    \"Requirements-based test\": {\n",
    "        ASIL.QM: MethodRecommendation.RECOMMENDED,\n",
    "        ASIL.A: MethodRecommendation.HIGHLY_RECOMMENDED,\n",
    "        ASIL.B: MethodRecommendation.HIGHLY_RECOMMENDED,\n",
    "        ASIL.C: MethodRecommendation.STRONGLY_RECOMMENDED,\n",
    "        ASIL.D: MethodRecommendation.STRONGLY_RECOMMENDED\n",
    "    },\n",
    "    \"Interface test\": {\n",
    "        ASIL.QM: MethodRecommendation.RECOMMENDED,\n",
    "        ASIL.A: MethodRecommendation.HIGHLY_RECOMMENDED,\n",
    "        ASIL.B: MethodRecommendation.HIGHLY_RECOMMENDED,\n",
    "        ASIL.C: MethodRecommendation.STRONGLY_RECOMMENDED,\n",
    "        ASIL.D: MethodRecommendation.STRONGLY_RECOMMENDED\n",
    "    },\n",
    "    \"Fault injection test\": {\n",
    "        ASIL.QM: MethodRecommendation.NOT_RECOMMENDED,\n",
    "        ASIL.A: MethodRecommendation.RECOMMENDED,\n",
    "        ASIL.B: MethodRecommendation.RECOMMENDED,\n",
    "        ASIL.C: MethodRecommendation.HIGHLY_RECOMMENDED,\n",
    "        ASIL.D: MethodRecommendation.HIGHLY_RECOMMENDED\n",
    "    },\n",
    "    \"Resource usage test\": {\n",
    "        ASIL.QM: MethodRecommendation.RECOMMENDED,\n",
    "        ASIL.A: MethodRecommendation.RECOMMENDED,\n",
    "        ASIL.B: MethodRecommendation.HIGHLY_RECOMMENDED,\n",
    "        ASIL.C: MethodRecommendation.HIGHLY_RECOMMENDED,\n",
    "        ASIL.D: MethodRecommendation.STRONGLY_RECOMMENDED\n",
    "    },\n",
    "    \"Back-to-back test\": {\n",
    "        ASIL.QM: MethodRecommendation.NOT_RECOMMENDED,\n",
    "        ASIL.A: MethodRecommendation.RECOMMENDED,\n",
    "        ASIL.B: MethodRecommendation.RECOMMENDED,\n",
    "        ASIL.C: MethodRecommendation.HIGHLY_RECOMMENDED,\n",
    "        ASIL.D: MethodRecommendation.HIGHLY_RECOMMENDED\n",
    "    }\n",
    "}\n",
    "\n",
    "# Coverage metrics per ASIL\n",
    "COVERAGE_REQUIREMENTS = {\n",
    "    \"Statement coverage\": {\n",
    "        ASIL.QM: MethodRecommendation.RECOMMENDED,\n",
    "        ASIL.A: MethodRecommendation.STRONGLY_RECOMMENDED,\n",
    "        ASIL.B: MethodRecommendation.STRONGLY_RECOMMENDED,\n",
    "        ASIL.C: MethodRecommendation.STRONGLY_RECOMMENDED,\n",
    "        ASIL.D: MethodRecommendation.STRONGLY_RECOMMENDED\n",
    "    },\n",
    "    \"Branch coverage\": {\n",
    "        ASIL.QM: MethodRecommendation.NOT_RECOMMENDED,\n",
    "        ASIL.A: MethodRecommendation.HIGHLY_RECOMMENDED,\n",
    "        ASIL.B: MethodRecommendation.STRONGLY_RECOMMENDED,\n",
    "        ASIL.C: MethodRecommendation.STRONGLY_RECOMMENDED,\n",
    "        ASIL.D: MethodRecommendation.STRONGLY_RECOMMENDED\n",
    "    },\n",
    "    \"MC/DC coverage\": {\n",
    "        ASIL.QM: MethodRecommendation.NOT_RECOMMENDED,\n",
    "        ASIL.A: MethodRecommendation.NOT_RECOMMENDED,\n",
    "        ASIL.B: MethodRecommendation.RECOMMENDED,\n",
    "        ASIL.C: MethodRecommendation.HIGHLY_RECOMMENDED,\n",
    "        ASIL.D: MethodRecommendation.STRONGLY_RECOMMENDED\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_recommended_methods(asil: ASIL) -> Dict[str, str]:\n",
    "    \"\"\"Get recommended verification methods for given ASIL.\"\"\"\n",
    "    methods = {}\n",
    "    for method, recommendations in VERIFICATION_METHODS.items():\n",
    "        if recommendations[asil] != MethodRecommendation.NOT_RECOMMENDED:\n",
    "            methods[method] = recommendations[asil].value\n",
    "    return methods\n",
    "\n",
    "def display_method_matrix():\n",
    "    \"\"\"Display verification method matrix.\"\"\"\n",
    "    print(\"Verification Methods per ASIL (ISO 26262-6 Table 9)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Method':<30} {'QM':^6} {'A':^6} {'B':^6} {'C':^6} {'D':^6}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for method, recs in VERIFICATION_METHODS.items():\n",
    "        row = f\"{method:<30}\"\n",
    "        for asil in ASIL:\n",
    "            row += f\" {recs[asil].value:^6}\"\n",
    "        print(row)\n",
    "    \n",
    "    print(\"\\nLegend: ++ strongly recommended, + highly recommended, o recommended, -- not recommended\")\n",
    "\n",
    "display_method_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Case Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SafetyRequirement:\n",
    "    \"\"\"Safety requirement from HARA/Safety Concept.\"\"\"\n",
    "    id: str\n",
    "    description: str\n",
    "    asil: ASIL\n",
    "    source: str  # e.g., \"SG-001\" (Safety Goal)\n",
    "    acceptance_criteria: str\n",
    "    \n",
    "@dataclass \n",
    "class TestCase:\n",
    "    \"\"\"Test case for verification.\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    requirement_id: str\n",
    "    preconditions: List[str]\n",
    "    test_steps: List[str]\n",
    "    expected_results: List[str]\n",
    "    test_type: str  # \"unit\", \"integration\", \"system\", \"acceptance\"\n",
    "    status: str = \"not_run\"  # \"not_run\", \"pass\", \"fail\", \"blocked\"\n",
    "    actual_results: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class TestSuite:\n",
    "    \"\"\"Collection of test cases for a component/feature.\"\"\"\n",
    "    name: str\n",
    "    component: str\n",
    "    requirements: List[SafetyRequirement] = field(default_factory=list)\n",
    "    test_cases: List[TestCase] = field(default_factory=list)\n",
    "    \n",
    "    def add_requirement(self, req: SafetyRequirement):\n",
    "        self.requirements.append(req)\n",
    "    \n",
    "    def add_test_case(self, tc: TestCase):\n",
    "        self.test_cases.append(tc)\n",
    "    \n",
    "    def get_traceability_matrix(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate requirements-to-tests traceability matrix.\"\"\"\n",
    "        matrix = []\n",
    "        for req in self.requirements:\n",
    "            tests = [tc.id for tc in self.test_cases if tc.requirement_id == req.id]\n",
    "            matrix.append({\n",
    "                'Requirement': req.id,\n",
    "                'ASIL': req.asil.name,\n",
    "                'Description': req.description[:50] + '...' if len(req.description) > 50 else req.description,\n",
    "                'Test Cases': ', '.join(tests) if tests else 'MISSING',\n",
    "                'Coverage': 'Covered' if tests else 'Not Covered'\n",
    "            })\n",
    "        return pd.DataFrame(matrix)\n",
    "    \n",
    "    def get_coverage_summary(self) -> Dict:\n",
    "        \"\"\"Calculate test coverage summary.\"\"\"\n",
    "        total_reqs = len(self.requirements)\n",
    "        covered_reqs = len(set(tc.requirement_id for tc in self.test_cases))\n",
    "        \n",
    "        total_tests = len(self.test_cases)\n",
    "        passed = len([tc for tc in self.test_cases if tc.status == 'pass'])\n",
    "        failed = len([tc for tc in self.test_cases if tc.status == 'fail'])\n",
    "        not_run = len([tc for tc in self.test_cases if tc.status == 'not_run'])\n",
    "        \n",
    "        return {\n",
    "            'total_requirements': total_reqs,\n",
    "            'covered_requirements': covered_reqs,\n",
    "            'requirement_coverage': covered_reqs / total_reqs * 100 if total_reqs > 0 else 0,\n",
    "            'total_tests': total_tests,\n",
    "            'passed': passed,\n",
    "            'failed': failed,\n",
    "            'not_run': not_run,\n",
    "            'pass_rate': passed / total_tests * 100 if total_tests > 0 else 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example: Object Detection V&V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test suite for object detection component\n",
    "detection_suite = TestSuite(\n",
    "    name=\"Object Detection Verification\",\n",
    "    component=\"Camera-based Object Detection\"\n",
    ")\n",
    "\n",
    "# Define safety requirements\n",
    "safety_requirements = [\n",
    "    SafetyRequirement(\n",
    "        id=\"SR-OD-001\",\n",
    "        description=\"The system shall detect pedestrians within 100m range with recall >= 99%\",\n",
    "        asil=ASIL.D,\n",
    "        source=\"SG-001\",\n",
    "        acceptance_criteria=\"Recall >= 99% on validation dataset (>10000 pedestrian instances)\"\n",
    "    ),\n",
    "    SafetyRequirement(\n",
    "        id=\"SR-OD-002\",\n",
    "        description=\"The system shall report detection confidence with calibration error < 5%\",\n",
    "        asil=ASIL.C,\n",
    "        source=\"SG-002\",\n",
    "        acceptance_criteria=\"Expected Calibration Error (ECE) < 0.05\"\n",
    "    ),\n",
    "    SafetyRequirement(\n",
    "        id=\"SR-OD-003\",\n",
    "        description=\"The system shall complete detection processing within 50ms per frame\",\n",
    "        asil=ASIL.B,\n",
    "        source=\"SG-003\",\n",
    "        acceptance_criteria=\"99th percentile latency < 50ms over 1000 frames\"\n",
    "    ),\n",
    "    SafetyRequirement(\n",
    "        id=\"SR-OD-004\",\n",
    "        description=\"The system shall indicate reduced confidence in adverse weather\",\n",
    "        asil=ASIL.C,\n",
    "        source=\"SG-004\",\n",
    "        acceptance_criteria=\"Mean confidence decreases by >= 20% in rain/fog conditions\"\n",
    "    ),\n",
    "    SafetyRequirement(\n",
    "        id=\"SR-OD-005\",\n",
    "        description=\"The system shall detect OOD inputs with AUROC >= 0.95\",\n",
    "        asil=ASIL.C,\n",
    "        source=\"SG-005\",\n",
    "        acceptance_criteria=\"AUROC >= 0.95 on OOD benchmark dataset\"\n",
    "    )\n",
    "]\n",
    "\n",
    "for req in safety_requirements:\n",
    "    detection_suite.add_requirement(req)\n",
    "\n",
    "print(f\"Loaded {len(detection_suite.requirements)} safety requirements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test cases\n",
    "test_cases = [\n",
    "    # Tests for SR-OD-001 (Pedestrian Detection)\n",
    "    TestCase(\n",
    "        id=\"TC-OD-001\",\n",
    "        name=\"Pedestrian recall on KITTI validation set\",\n",
    "        requirement_id=\"SR-OD-001\",\n",
    "        preconditions=[\"Model loaded\", \"KITTI validation set available\"],\n",
    "        test_steps=[\n",
    "            \"Load all images with pedestrian annotations\",\n",
    "            \"Run inference on each image\",\n",
    "            \"Match predictions to ground truth (IoU > 0.5)\",\n",
    "            \"Calculate recall\"\n",
    "        ],\n",
    "        expected_results=[\"Recall >= 99%\"],\n",
    "        test_type=\"system\",\n",
    "        status=\"pass\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        id=\"TC-OD-002\",\n",
    "        name=\"Pedestrian detection in low light\",\n",
    "        requirement_id=\"SR-OD-001\",\n",
    "        preconditions=[\"Model loaded\", \"Low-light test set available\"],\n",
    "        test_steps=[\n",
    "            \"Load images with brightness < 50 lux\",\n",
    "            \"Run inference\",\n",
    "            \"Calculate recall for pedestrians\"\n",
    "        ],\n",
    "        expected_results=[\"Recall >= 95% in low light (degraded mode accepted)\"],\n",
    "        test_type=\"system\",\n",
    "        status=\"pass\"\n",
    "    ),\n",
    "    # Tests for SR-OD-002 (Calibration)\n",
    "    TestCase(\n",
    "        id=\"TC-OD-003\",\n",
    "        name=\"Confidence calibration measurement\",\n",
    "        requirement_id=\"SR-OD-002\",\n",
    "        preconditions=[\"Model loaded\", \"Validation set with labels\"],\n",
    "        test_steps=[\n",
    "            \"Collect predictions with confidence scores\",\n",
    "            \"Bin predictions by confidence (10 bins)\",\n",
    "            \"Calculate accuracy per bin\",\n",
    "            \"Compute ECE = sum(|accuracy - confidence| * bin_weight)\"\n",
    "        ],\n",
    "        expected_results=[\"ECE < 0.05\"],\n",
    "        test_type=\"system\",\n",
    "        status=\"fail\",\n",
    "        actual_results=\"ECE = 0.08 - calibration needed\"\n",
    "    ),\n",
    "    # Tests for SR-OD-003 (Latency)\n",
    "    TestCase(\n",
    "        id=\"TC-OD-004\",\n",
    "        name=\"Inference latency measurement\",\n",
    "        requirement_id=\"SR-OD-003\",\n",
    "        preconditions=[\"Model deployed on target hardware\", \"Test images loaded\"],\n",
    "        test_steps=[\n",
    "            \"Warm up model with 100 inferences\",\n",
    "            \"Measure latency for 1000 frames\",\n",
    "            \"Calculate 99th percentile\"\n",
    "        ],\n",
    "        expected_results=[\"P99 latency < 50ms\"],\n",
    "        test_type=\"integration\",\n",
    "        status=\"pass\"\n",
    "    ),\n",
    "    # Tests for SR-OD-004 (Weather awareness)\n",
    "    TestCase(\n",
    "        id=\"TC-OD-005\",\n",
    "        name=\"Confidence reduction in rain\",\n",
    "        requirement_id=\"SR-OD-004\",\n",
    "        preconditions=[\"Model loaded\", \"Rain simulation dataset\"],\n",
    "        test_steps=[\n",
    "            \"Compare confidence on clear vs rain images\",\n",
    "            \"Calculate mean confidence difference\"\n",
    "        ],\n",
    "        expected_results=[\"Confidence reduced by >= 20%\"],\n",
    "        test_type=\"system\",\n",
    "        status=\"pass\"\n",
    "    ),\n",
    "    # Tests for SR-OD-005 (OOD Detection)\n",
    "    TestCase(\n",
    "        id=\"TC-OD-006\",\n",
    "        name=\"OOD detection AUROC measurement\",\n",
    "        requirement_id=\"SR-OD-005\",\n",
    "        preconditions=[\"OOD detector deployed\", \"ID and OOD test sets\"],\n",
    "        test_steps=[\n",
    "            \"Compute OOD scores for in-distribution samples\",\n",
    "            \"Compute OOD scores for out-of-distribution samples\",\n",
    "            \"Calculate AUROC\"\n",
    "        ],\n",
    "        expected_results=[\"AUROC >= 0.95\"],\n",
    "        test_type=\"system\",\n",
    "        status=\"not_run\"\n",
    "    )\n",
    "]\n",
    "\n",
    "for tc in test_cases:\n",
    "    detection_suite.add_test_case(tc)\n",
    "\n",
    "print(f\"Loaded {len(detection_suite.test_cases)} test cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display traceability matrix\n",
    "print(\"Requirements Traceability Matrix\")\n",
    "print(\"=\" * 90)\n",
    "traceability = detection_suite.get_traceability_matrix()\n",
    "print(traceability.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display coverage summary\n",
    "summary = detection_suite.get_coverage_summary()\n",
    "\n",
    "print(\"\\nTest Coverage Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Requirement Coverage: {summary['covered_requirements']}/{summary['total_requirements']} ({summary['requirement_coverage']:.1f}%)\")\n",
    "print(f\"Test Execution: {summary['passed'] + summary['failed']}/{summary['total_tests']} executed\")\n",
    "print(f\"  Passed: {summary['passed']}\")\n",
    "print(f\"  Failed: {summary['failed']}\")\n",
    "print(f\"  Not Run: {summary['not_run']}\")\n",
    "print(f\"Pass Rate: {summary['pass_rate']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Code Coverage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CoverageReport:\n",
    "    \"\"\"Simulated code coverage report.\"\"\"\n",
    "    module: str\n",
    "    statement_coverage: float\n",
    "    branch_coverage: float\n",
    "    mcdc_coverage: float\n",
    "    uncovered_lines: List[int] = field(default_factory=list)\n",
    "\n",
    "def evaluate_coverage_compliance(report: CoverageReport, asil: ASIL) -> Dict:\n",
    "    \"\"\"Evaluate coverage against ISO 26262 requirements.\"\"\"\n",
    "    results = {\n",
    "        'module': report.module,\n",
    "        'asil': asil.name,\n",
    "        'checks': []\n",
    "    }\n",
    "    \n",
    "    # Statement coverage (required for all ASILs)\n",
    "    stmt_required = 100  # Target 100% for safety-critical\n",
    "    stmt_pass = report.statement_coverage >= stmt_required\n",
    "    results['checks'].append({\n",
    "        'metric': 'Statement Coverage',\n",
    "        'required': f'>= {stmt_required}%',\n",
    "        'actual': f'{report.statement_coverage:.1f}%',\n",
    "        'status': 'PASS' if stmt_pass else 'FAIL'\n",
    "    })\n",
    "    \n",
    "    # Branch coverage (ASIL A and above)\n",
    "    if asil.value >= ASIL.A.value:\n",
    "        branch_required = 100\n",
    "        branch_pass = report.branch_coverage >= branch_required\n",
    "        results['checks'].append({\n",
    "            'metric': 'Branch Coverage',\n",
    "            'required': f'>= {branch_required}%',\n",
    "            'actual': f'{report.branch_coverage:.1f}%',\n",
    "            'status': 'PASS' if branch_pass else 'FAIL'\n",
    "        })\n",
    "    \n",
    "    # MC/DC coverage (ASIL C and D)\n",
    "    if asil.value >= ASIL.C.value:\n",
    "        mcdc_required = 100\n",
    "        mcdc_pass = report.mcdc_coverage >= mcdc_required\n",
    "        results['checks'].append({\n",
    "            'metric': 'MC/DC Coverage',\n",
    "            'required': f'>= {mcdc_required}%',\n",
    "            'actual': f'{report.mcdc_coverage:.1f}%',\n",
    "            'status': 'PASS' if mcdc_pass else 'FAIL'\n",
    "        })\n",
    "    \n",
    "    results['overall'] = all(c['status'] == 'PASS' for c in results['checks'])\n",
    "    return results\n",
    "\n",
    "# Example coverage reports\n",
    "coverage_reports = [\n",
    "    CoverageReport(\"preprocessing.py\", 98.5, 95.2, 88.3, [45, 67, 89]),\n",
    "    CoverageReport(\"detection_model.py\", 100.0, 100.0, 95.5, []),\n",
    "    CoverageReport(\"postprocessing.py\", 97.8, 92.1, 85.0, [23, 56, 78, 112]),\n",
    "    CoverageReport(\"safety_monitor.py\", 100.0, 100.0, 100.0, [])\n",
    "]\n",
    "\n",
    "print(\"Coverage Compliance Analysis (ASIL C)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for report in coverage_reports:\n",
    "    result = evaluate_coverage_compliance(report, ASIL.C)\n",
    "    status = \"COMPLIANT\" if result['overall'] else \"NON-COMPLIANT\"\n",
    "    print(f\"\\n{report.module}: {status}\")\n",
    "    for check in result['checks']:\n",
    "        print(f\"  {check['metric']}: {check['actual']} (req: {check['required']}) - {check['status']}\")\n",
    "    if report.uncovered_lines:\n",
    "        print(f\"  Uncovered lines: {report.uncovered_lines}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fault Injection Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FaultInjectionTest:\n",
    "    \"\"\"Fault injection test specification.\"\"\"\n",
    "    id: str\n",
    "    fault_type: str\n",
    "    injection_point: str\n",
    "    expected_detection: str\n",
    "    expected_reaction: str\n",
    "    result: Optional[str] = None\n",
    "\n",
    "def simulate_fault_injection_campaign() -> List[FaultInjectionTest]:\n",
    "    \"\"\"Define fault injection test campaign for perception system.\"\"\"\n",
    "    tests = [\n",
    "        FaultInjectionTest(\n",
    "            id=\"FI-001\",\n",
    "            fault_type=\"Sensor data loss\",\n",
    "            injection_point=\"Camera input interface\",\n",
    "            expected_detection=\"Within 100ms\",\n",
    "            expected_reaction=\"Switch to degraded mode, use LiDAR only\",\n",
    "            result=\"Detected in 45ms, failover successful\"\n",
    "        ),\n",
    "        FaultInjectionTest(\n",
    "            id=\"FI-002\",\n",
    "            fault_type=\"Bit flip in detection output\",\n",
    "            injection_point=\"Neural network output buffer\",\n",
    "            expected_detection=\"CRC check failure\",\n",
    "            expected_reaction=\"Discard corrupted frame, use previous\",\n",
    "            result=\"CRC detected corruption, frame discarded\"\n",
    "        ),\n",
    "        FaultInjectionTest(\n",
    "            id=\"FI-003\",\n",
    "            fault_type=\"Processing timeout\",\n",
    "            injection_point=\"Inference engine\",\n",
    "            expected_detection=\"Watchdog timeout at 60ms\",\n",
    "            expected_reaction=\"Signal timeout to planning module\",\n",
    "            result=\"Watchdog triggered at 60ms, timeout signaled\"\n",
    "        ),\n",
    "        FaultInjectionTest(\n",
    "            id=\"FI-004\",\n",
    "            fault_type=\"Memory corruption\",\n",
    "            injection_point=\"Model weights memory\",\n",
    "            expected_detection=\"Checksum verification failure\",\n",
    "            expected_reaction=\"Reload model from secure storage\",\n",
    "            result=\"Checksum mismatch detected, model reloaded\"\n",
    "        ),\n",
    "        FaultInjectionTest(\n",
    "            id=\"FI-005\",\n",
    "            fault_type=\"Calibration data corruption\",\n",
    "            injection_point=\"Camera calibration matrix\",\n",
    "            expected_detection=\"Plausibility check failure\",\n",
    "            expected_reaction=\"Use backup calibration, request service\",\n",
    "            result=\"Plausibility check passed (fault not severe enough)\"\n",
    "        )\n",
    "    ]\n",
    "    return tests\n",
    "\n",
    "fi_tests = simulate_fault_injection_campaign()\n",
    "\n",
    "print(\"Fault Injection Test Results\")\n",
    "print(\"=\" * 80)\n",
    "for test in fi_tests:\n",
    "    print(f\"\\n{test.id}: {test.fault_type}\")\n",
    "    print(f\"  Injection Point: {test.injection_point}\")\n",
    "    print(f\"  Expected Detection: {test.expected_detection}\")\n",
    "    print(f\"  Expected Reaction: {test.expected_reaction}\")\n",
    "    print(f\"  Result: {test.result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. V&V Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vv_dashboard(suite: TestSuite, coverage_reports: List[CoverageReport]):\n",
    "    \"\"\"Create V&V status dashboard.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Test Execution Status\n",
    "    ax1 = axes[0, 0]\n",
    "    summary = suite.get_coverage_summary()\n",
    "    statuses = [summary['passed'], summary['failed'], summary['not_run']]\n",
    "    labels = ['Passed', 'Failed', 'Not Run']\n",
    "    colors = ['#4caf50', '#f44336', '#9e9e9e']\n",
    "    ax1.pie(statuses, labels=labels, colors=colors, autopct='%1.0f%%', startangle=90)\n",
    "    ax1.set_title('Test Execution Status')\n",
    "    \n",
    "    # 2. Requirements Coverage by ASIL\n",
    "    ax2 = axes[0, 1]\n",
    "    asil_coverage = {}\n",
    "    for req in suite.requirements:\n",
    "        asil_name = req.asil.name\n",
    "        if asil_name not in asil_coverage:\n",
    "            asil_coverage[asil_name] = {'total': 0, 'covered': 0}\n",
    "        asil_coverage[asil_name]['total'] += 1\n",
    "        if any(tc.requirement_id == req.id for tc in suite.test_cases):\n",
    "            asil_coverage[asil_name]['covered'] += 1\n",
    "    \n",
    "    asils = list(asil_coverage.keys())\n",
    "    covered = [asil_coverage[a]['covered'] for a in asils]\n",
    "    total = [asil_coverage[a]['total'] for a in asils]\n",
    "    \n",
    "    x = np.arange(len(asils))\n",
    "    width = 0.35\n",
    "    ax2.bar(x - width/2, total, width, label='Total', color='#2196f3')\n",
    "    ax2.bar(x + width/2, covered, width, label='Covered', color='#4caf50')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(asils)\n",
    "    ax2.set_ylabel('Requirements')\n",
    "    ax2.set_title('Requirements Coverage by ASIL')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Code Coverage by Module\n",
    "    ax3 = axes[1, 0]\n",
    "    modules = [r.module for r in coverage_reports]\n",
    "    stmt_cov = [r.statement_coverage for r in coverage_reports]\n",
    "    branch_cov = [r.branch_coverage for r in coverage_reports]\n",
    "    mcdc_cov = [r.mcdc_coverage for r in coverage_reports]\n",
    "    \n",
    "    x = np.arange(len(modules))\n",
    "    width = 0.25\n",
    "    ax3.bar(x - width, stmt_cov, width, label='Statement', color='#2196f3')\n",
    "    ax3.bar(x, branch_cov, width, label='Branch', color='#ff9800')\n",
    "    ax3.bar(x + width, mcdc_cov, width, label='MC/DC', color='#9c27b0')\n",
    "    ax3.axhline(y=100, color='r', linestyle='--', label='Target')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels([m.replace('.py', '') for m in modules], rotation=45, ha='right')\n",
    "    ax3.set_ylabel('Coverage %')\n",
    "    ax3.set_ylim(0, 110)\n",
    "    ax3.set_title('Code Coverage by Module')\n",
    "    ax3.legend(fontsize=8)\n",
    "    \n",
    "    # 4. V&V Progress Timeline (simulated)\n",
    "    ax4 = axes[1, 1]\n",
    "    phases = ['Unit Test', 'Integration', 'System', 'Acceptance']\n",
    "    planned = [100, 80, 60, 40]\n",
    "    actual = [100, 75, 45, 20]\n",
    "    \n",
    "    x = np.arange(len(phases))\n",
    "    ax4.barh(x, planned, height=0.4, label='Planned', color='#bbdefb', align='center')\n",
    "    ax4.barh(x, actual, height=0.4, label='Completed', color='#1976d2', align='center')\n",
    "    ax4.set_yticks(x)\n",
    "    ax4.set_yticklabels(phases)\n",
    "    ax4.set_xlabel('Progress %')\n",
    "    ax4.set_title('V&V Phase Progress')\n",
    "    ax4.legend(loc='lower right')\n",
    "    ax4.set_xlim(0, 110)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_vv_dashboard(detection_suite, coverage_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways\n",
    "\n",
    "### V&V Planning\n",
    "\n",
    "1. **Start with requirements**: All tests trace to safety requirements\n",
    "2. **Match methods to ASIL**: Higher ASIL = more rigorous testing\n",
    "3. **Coverage targets**: Statement, branch, MC/DC as appropriate\n",
    "4. **Fault injection**: Essential for ASIL C/D safety mechanisms\n",
    "\n",
    "### Test Design Principles\n",
    "\n",
    "- **Requirements-based**: Every requirement has test coverage\n",
    "- **Boundary values**: Test at limits of valid ranges\n",
    "- **Negative testing**: Verify proper handling of invalid inputs\n",
    "- **Regression**: Maintain test suite for continuous verification\n",
    "\n",
    "### Documentation Requirements\n",
    "\n",
    "| Document | Purpose |\n",
    "|----------|--------|\n",
    "| Test Plan | Overall V&V strategy |\n",
    "| Test Specification | Detailed test cases |\n",
    "| Test Report | Execution results |\n",
    "| Traceability Matrix | Requirements to tests |\n",
    "| Coverage Report | Code coverage metrics |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. ISO 26262:2018 - Part 4 (Product development at the system level)\n",
    "2. ISO 26262:2018 - Part 6 (Product development at the software level)\n",
    "3. DO-178C - Software Considerations in Airborne Systems (MC/DC reference)\n",
    "4. ISTQB - Software Testing Body of Knowledge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
